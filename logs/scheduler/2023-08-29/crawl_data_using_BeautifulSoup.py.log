[2023-08-29T03:23:07.504+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:23:07.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:23:07.519+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:23:07.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:23:08.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:23:08.548+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:23:08.547+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:23:08.584+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:23:08.583+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:23:08.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.131 seconds
[2023-08-29T03:23:39.187+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:23:39.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:23:39.204+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:23:39.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:23:39.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:23:39.662+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:23:39.661+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:23:39.680+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:23:39.680+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:23:39.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.514 seconds
[2023-08-29T03:24:09.816+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:24:09.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:24:09.832+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:24:09.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:24:10.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:24:10.168+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:24:10.167+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:24:10.219+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:24:10.219+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:24:10.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.453 seconds
[2023-08-29T03:24:40.517+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:24:40.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:24:40.547+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:24:40.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:24:40.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:24:40.763+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:24:40.762+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:24:40.787+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:24:40.787+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:24:40.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.299 seconds
[2023-08-29T03:25:11.126+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:25:11.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:25:11.138+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:25:11.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:25:11.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:25:11.351+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:25:11.350+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:25:11.373+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:25:11.373+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:25:11.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.272 seconds
[2023-08-29T03:25:41.758+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:25:41.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:25:41.769+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:25:41.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:25:41.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:25:41.977+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:25:41.976+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:25:42.007+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:25:42.006+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:25:42.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.279 seconds
[2023-08-29T03:26:12.442+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:26:12.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:26:12.458+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:26:12.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:26:12.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:26:12.651+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:26:12.650+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:26:12.672+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:26:12.672+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:26:12.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.257 seconds
[2023-08-29T03:26:43.210+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:26:43.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:26:43.257+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:26:43.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:26:43.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:26:43.703+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:26:43.701+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:26:43.734+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:26:43.734+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:26:43.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.563 seconds
[2023-08-29T03:27:14.217+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:27:14.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:27:14.230+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:27:14.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:27:14.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:27:14.410+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:27:14.409+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:27:14.433+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:27:14.433+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:27:14.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.244 seconds
[2023-08-29T03:27:44.851+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:27:44.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:27:44.867+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:27:44.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:27:45.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:27:45.065+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:27:45.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:27:45.099+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:27:45.099+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:27:45.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.277 seconds
[2023-08-29T03:28:15.601+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:28:15.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:28:15.616+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:28:15.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:28:15.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:28:15.784+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:28:15.783+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:28:15.805+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:28:15.805+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:28:15.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.225 seconds
[2023-08-29T03:28:46.199+0000] {processor.py:157} INFO - Started process (PID=129) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:28:46.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:28:46.217+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:28:46.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:28:46.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:28:46.457+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:28:46.456+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:28:46.494+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:28:46.493+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:28:46.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.321 seconds
[2023-08-29T03:29:16.867+0000] {processor.py:157} INFO - Started process (PID=137) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:29:16.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:29:16.880+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:29:16.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:29:17.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:29:17.131+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:29:17.131+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:29:17.153+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:29:17.153+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:29:17.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.318 seconds
[2023-08-29T03:29:47.559+0000] {processor.py:157} INFO - Started process (PID=146) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:29:47.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:29:47.576+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:29:47.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:29:47.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:29:47.803+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:29:47.802+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:29:47.833+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:29:47.833+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:29:47.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.302 seconds
[2023-08-29T03:30:18.569+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:30:18.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T03:30:18.610+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:30:18.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:30:18.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T03:30:18.928+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:30:18.927+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T03:30:18.969+0000] {logging_mixin.py:151} INFO - [2023-08-29T03:30:18.969+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T03:30:18.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.446 seconds
[2023-08-29T04:46:37.924+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:46:37.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:46:37.952+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:46:37.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:46:40.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:46:41.323+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:46:41.322+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:46:41.391+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:46:41.391+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:46:41.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 3.594 seconds
[2023-08-29T04:47:12.439+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:47:12.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:47:12.459+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:47:12.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:47:15.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:47:15.191+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:47:15.190+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:47:15.258+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:47:15.258+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:47:15.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.895 seconds
[2023-08-29T04:47:45.832+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:47:45.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:47:45.840+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:47:45.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:47:45.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:47:46.006+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:47:46.006+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:47:46.029+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:47:46.028+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:47:46.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.226 seconds
[2023-08-29T04:48:16.278+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:48:16.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:48:16.301+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:48:16.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:48:16.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:48:16.554+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:48:16.553+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:48:16.574+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:48:16.574+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:48:16.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.342 seconds
[2023-08-29T04:48:35.150+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:48:35.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:48:35.162+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:48:35.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:48:35.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:48:35.401+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:48:35.400+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:48:35.434+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:48:35.433+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:48:35.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.322 seconds
[2023-08-29T04:49:05.913+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:49:05.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:49:05.924+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:49:05.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:49:06.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:49:06.177+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:49:06.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:49:06.227+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:49:06.227+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:49:06.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.346 seconds
[2023-08-29T04:51:42.793+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:51:42.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:51:42.818+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:51:42.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:51:43.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:51:43.678+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:51:43.677+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:51:43.738+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:51:43.737+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:51:43.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.020 seconds
[2023-08-29T04:52:14.190+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:52:14.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:52:14.210+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:52:14.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:52:14.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:52:14.753+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:52:14.753+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:52:15.274+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:52:15.273+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:52:15.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.210 seconds
[2023-08-29T04:52:46.184+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:52:46.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:52:46.203+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:52:46.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:52:46.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:52:46.484+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:52:46.483+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:52:46.506+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:52:46.506+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:52:46.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.345 seconds
[2023-08-29T04:53:50.208+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:53:50.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:53:50.225+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:53:50.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:53:50.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:53:51.252+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:53:51.250+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:53:51.301+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:53:51.301+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:53:51.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.186 seconds
[2023-08-29T04:53:52.413+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:53:52.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:53:52.431+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:53:52.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:53:53.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:53:53.218+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:53:53.217+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:53:53.282+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:53:53.282+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:53:53.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.930 seconds
[2023-08-29T04:54:23.536+0000] {processor.py:157} INFO - Started process (PID=41) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:54:23.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:54:23.546+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:54:23.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:54:23.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:54:24.038+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:54:24.036+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:54:24.070+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:54:24.070+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:54:24.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.561 seconds
[2023-08-29T04:54:55.013+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:54:55.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:54:55.035+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:54:55.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:54:55.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:54:55.468+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:54:55.467+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:54:55.506+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:54:55.506+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:54:55.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.568 seconds
[2023-08-29T04:55:52.393+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:55:52.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:55:52.405+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:55:52.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:55:53.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:55:53.916+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:55:53.915+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:55:54.054+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:55:54.053+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:55:54.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.857 seconds
[2023-08-29T04:56:24.543+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:56:24.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:56:24.597+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:56:24.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:56:25.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:56:25.761+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:56:25.761+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:56:25.791+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:56:25.791+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:56:25.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.296 seconds
[2023-08-29T04:56:56.079+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:56:56.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:56:56.098+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:56:56.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:56:56.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:56:56.713+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:56:56.712+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:56:56.731+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:56:56.731+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:56:56.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.679 seconds
[2023-08-29T04:57:27.411+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:57:27.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:57:27.424+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:57:27.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:57:27.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:57:27.945+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:57:27.944+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:57:27.968+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:57:27.968+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:57:27.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.601 seconds
[2023-08-29T04:57:58.753+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:57:58.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:57:58.763+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:57:58.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:57:59.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:57:59.176+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:57:59.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:57:59.200+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:57:59.200+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:57:59.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.470 seconds
[2023-08-29T04:58:29.773+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:58:29.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:58:29.788+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:58:29.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:58:31.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:58:31.560+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:58:31.555+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:58:31.678+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:58:31.677+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:58:31.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.176 seconds
[2023-08-29T04:59:02.662+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:59:02.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:59:02.674+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:59:02.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:59:03.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:59:03.063+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:59:03.063+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:59:03.081+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:59:03.081+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:59:03.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.440 seconds
[2023-08-29T04:59:33.976+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:59:33.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T04:59:33.994+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:59:33.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:59:34.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T04:59:34.236+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:59:34.235+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T04:59:34.260+0000] {logging_mixin.py:151} INFO - [2023-08-29T04:59:34.259+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T04:59:34.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.327 seconds
[2023-08-29T05:00:04.768+0000] {processor.py:157} INFO - Started process (PID=100) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:00:04.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:00:04.790+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:00:04.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:00:05.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:00:05.052+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:00:05.052+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:00:05.083+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:00:05.082+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:00:05.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.365 seconds
[2023-08-29T05:03:04.266+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:03:04.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:03:04.324+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:03:04.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:03:06.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:03:07.220+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:03:07.215+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:03:07.377+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:03:07.376+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:03:07.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 3.307 seconds
[2023-08-29T05:03:38.472+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:03:38.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:03:38.504+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:03:38.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:03:40.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:03:40.902+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:03:40.900+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:03:41.153+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:03:41.149+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:03:41.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.788 seconds
[2023-08-29T05:04:08.968+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:04:08.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:04:08.982+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:04:08.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:04:09.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:04:09.466+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:04:09.465+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:04:09.487+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:04:09.487+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:04:09.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.550 seconds
[2023-08-29T05:05:12.491+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:05:12.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:05:12.503+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:05:12.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:05:15.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:05:18.037+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:05:18.032+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:05:18.113+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:05:18.113+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:05:18.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 5.723 seconds
[2023-08-29T05:05:48.681+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:05:48.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:05:48.914+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:05:48.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:05:51.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:05:51.474+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:05:51.473+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:05:51.506+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:05:51.505+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:05:51.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.885 seconds
[2023-08-29T05:06:21.870+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:06:21.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:06:21.884+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:06:21.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:06:22.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:06:22.145+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:06:22.144+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:06:22.166+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:06:22.166+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:06:22.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.317 seconds
[2023-08-29T05:06:52.434+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:06:52.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:06:52.441+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:06:52.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:06:52.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:06:52.728+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:06:52.728+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:06:52.750+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:06:52.750+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:06:52.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.349 seconds
[2023-08-29T05:07:23.183+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:07:23.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:07:23.192+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:07:23.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:07:23.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:07:23.669+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:07:23.668+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:07:23.691+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:07:23.691+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:07:23.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.542 seconds
[2023-08-29T05:07:54.188+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:07:54.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:07:54.203+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:07:54.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:07:54.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:07:54.656+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:07:54.656+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:07:54.690+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:07:54.690+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:07:54.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.534 seconds
[2023-08-29T05:08:25.060+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:08:25.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:08:25.074+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:08:25.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:08:26.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:08:26.394+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:08:26.391+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:08:26.465+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:08:26.465+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:08:26.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.464 seconds
[2023-08-29T05:08:57.245+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:08:57.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:08:57.258+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:08:57.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:08:57.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:08:57.420+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:08:57.419+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:08:57.441+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:08:57.440+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:08:57.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.218 seconds
[2023-08-29T05:09:27.925+0000] {processor.py:157} INFO - Started process (PID=98) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:09:27.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:09:27.938+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:09:27.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:09:28.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:09:28.138+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:09:28.137+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:09:28.160+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:09:28.160+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:09:28.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.270 seconds
[2023-08-29T05:09:58.523+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:09:58.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:09:58.533+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:09:58.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:09:58.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:09:58.728+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:09:58.727+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:09:58.755+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:09:58.755+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:09:58.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.267 seconds
[2023-08-29T05:10:29.282+0000] {processor.py:157} INFO - Started process (PID=116) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:10:29.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:10:29.314+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:10:29.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:10:29.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:10:29.530+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:10:29.529+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:10:29.551+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:10:29.551+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:10:29.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.308 seconds
[2023-08-29T05:11:00.417+0000] {processor.py:157} INFO - Started process (PID=125) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:11:00.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:11:00.436+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:11:00.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:11:00.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:11:00.666+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:11:00.664+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:11:00.704+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:11:00.703+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:11:00.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.327 seconds
[2023-08-29T05:11:31.492+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:11:31.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:11:31.526+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:11:31.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:11:31.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:11:31.753+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:11:31.753+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:11:31.779+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:11:31.779+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:11:31.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.333 seconds
[2023-08-29T05:12:02.642+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:12:02.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:12:02.669+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:12:02.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:12:03.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:12:03.316+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:12:03.315+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:12:03.368+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:12:03.368+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:12:03.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.858 seconds
[2023-08-29T05:12:33.689+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:12:33.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:12:33.699+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:12:33.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:12:33.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:12:33.912+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:12:33.911+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:12:33.938+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:12:33.938+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:12:33.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.274 seconds
[2023-08-29T05:13:04.399+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:13:04.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:13:04.415+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:13:04.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:13:04.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:13:04.608+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:13:04.607+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:13:04.631+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:13:04.631+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:13:04.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.277 seconds
[2023-08-29T05:13:35.109+0000] {processor.py:157} INFO - Started process (PID=177) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:13:35.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:13:35.133+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:13:35.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:13:35.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:13:35.330+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:13:35.330+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:13:35.351+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:13:35.351+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:13:35.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.273 seconds
[2023-08-29T05:14:05.757+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:14:05.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:14:05.773+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:14:05.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:14:05.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:14:05.962+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:14:05.962+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:14:05.984+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:14:05.983+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:14:05.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.250 seconds
[2023-08-29T05:14:36.522+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:14:36.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:14:36.556+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:14:36.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:14:36.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:14:36.853+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:14:36.852+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:14:36.882+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:14:36.882+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:14:36.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.395 seconds
[2023-08-29T05:15:07.210+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:15:07.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:15:07.222+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:15:07.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:15:07.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:15:07.432+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:15:07.432+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:15:07.454+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:15:07.454+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:15:07.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.269 seconds
[2023-08-29T05:15:37.904+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:15:37.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T05:15:37.926+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:15:37.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:15:38.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T05:15:38.143+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:15:38.142+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T05:15:38.174+0000] {logging_mixin.py:151} INFO - [2023-08-29T05:15:38.174+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T05:15:38.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.300 seconds
[2023-08-29T09:53:43.338+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:53:43.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:53:43.357+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:53:43.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:53:44.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:53:44.266+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:53:44.265+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:53:44.301+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:53:44.300+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:53:44.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.025 seconds
[2023-08-29T09:54:14.764+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:54:14.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:54:14.784+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:54:14.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:54:15.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:54:15.224+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:54:15.224+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:54:15.242+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:54:15.241+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:54:15.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.503 seconds
[2023-08-29T09:54:45.497+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:54:45.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:54:45.528+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:54:45.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:54:45.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:54:45.775+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:54:45.774+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:54:45.799+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:54:45.798+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:54:45.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.330 seconds
[2023-08-29T09:55:16.247+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:55:16.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:55:16.269+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:55:16.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:55:16.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:55:16.521+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:55:16.520+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:55:16.553+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:55:16.553+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:55:16.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.371 seconds
[2023-08-29T09:55:47.090+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:55:47.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:55:47.105+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:55:47.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:55:47.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:55:47.314+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:55:47.313+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:55:47.351+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:55:47.350+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:55:47.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.324 seconds
[2023-08-29T09:56:56.512+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:56:56.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:56:56.539+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:56:56.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:56:57.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:56:57.417+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:56:57.416+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:56:57.463+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:56:57.463+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:56:57.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.157 seconds
[2023-08-29T09:57:28.217+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:57:28.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:57:28.228+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:57:28.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:57:28.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:57:28.656+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:57:28.655+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:57:28.679+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:57:28.679+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:57:28.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.488 seconds
[2023-08-29T09:57:59.022+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:57:59.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:57:59.056+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:57:59.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:57:59.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:57:59.601+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:57:59.601+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:57:59.622+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:57:59.622+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:57:59.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.631 seconds
[2023-08-29T09:58:30.202+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:58:30.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:58:30.220+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:58:30.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:58:32.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:58:32.767+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:58:32.764+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:58:32.926+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:58:32.926+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:58:32.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.793 seconds
[2023-08-29T09:59:03.428+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:59:03.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:59:03.450+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:59:03.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:59:03.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:59:03.932+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:59:03.932+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:59:03.958+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:59:03.958+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:59:03.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.568 seconds
[2023-08-29T09:59:34.204+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:59:34.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T09:59:34.237+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:59:34.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:59:34.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T09:59:34.784+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:59:34.783+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T09:59:34.803+0000] {logging_mixin.py:151} INFO - [2023-08-29T09:59:34.803+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T09:59:34.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.629 seconds
[2023-08-29T10:00:05.254+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:00:05.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:00:05.269+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:00:05.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:00:05.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:00:05.748+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:00:05.747+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:00:05.768+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:00:05.768+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:00:05.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.544 seconds
[2023-08-29T10:00:36.259+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:00:36.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:00:36.290+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:00:36.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:00:36.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:00:36.618+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:00:36.618+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:00:36.655+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:00:36.655+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:00:36.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.431 seconds
[2023-08-29T10:01:07.095+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:01:07.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:01:07.108+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:01:07.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:01:07.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:01:07.314+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:01:07.313+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:01:07.339+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:01:07.339+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:01:07.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.275 seconds
[2023-08-29T10:10:20.568+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:10:20.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:10:20.582+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:10:20.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:10:21.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:10:21.419+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:10:21.417+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:10:21.457+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:10:21.457+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:10:21.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.980 seconds
[2023-08-29T10:10:51.949+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:10:51.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:10:51.960+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:10:51.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:10:52.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:10:52.316+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:10:52.316+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:10:52.336+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:10:52.335+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:10:52.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.410 seconds
[2023-08-29T10:11:22.867+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:11:22.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:11:22.893+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:11:22.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:11:23.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:11:24.022+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:11:24.022+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:11:24.050+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:11:24.050+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:11:24.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.293 seconds
[2023-08-29T10:11:54.491+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:11:54.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:11:54.504+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:11:54.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:11:55.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:11:55.161+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:11:55.161+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:11:55.180+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:11:55.180+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:11:55.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.716 seconds
[2023-08-29T10:12:25.799+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:12:25.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:12:25.833+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:12:25.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:12:26.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:12:26.563+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:12:26.563+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:12:26.592+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:12:26.592+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:12:26.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.835 seconds
[2023-08-29T10:12:57.112+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:12:57.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:12:57.132+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:12:57.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:12:57.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:12:57.609+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:12:57.609+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:12:57.628+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:12:57.628+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:12:57.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.566 seconds
[2023-08-29T10:13:28.269+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:13:28.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:13:28.284+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:13:28.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:13:28.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:13:28.743+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:13:28.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:13:28.767+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:13:28.766+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:13:28.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.524 seconds
[2023-08-29T10:13:59.128+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:13:59.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:13:59.156+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:13:59.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:13:59.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:13:59.376+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:13:59.376+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:13:59.403+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:13:59.403+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:13:59.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.308 seconds
[2023-08-29T10:14:29.862+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:14:29.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:14:29.874+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:14:29.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:14:30.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:14:30.056+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:14:30.055+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:14:30.077+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:14:30.077+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:14:30.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.242 seconds
[2023-08-29T10:15:00.447+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:00.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:15:00.463+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:00.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:00.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:00.936+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:00.935+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:15:01.065+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:01.064+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:15:01.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.701 seconds
[2023-08-29T10:15:31.708+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:31.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:15:31.743+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:31.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:31.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:32.054+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:32.054+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:15:32.089+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:32.088+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:15:32.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.451 seconds
[2023-08-29T10:15:49.374+0000] {processor.py:157} INFO - Started process (PID=129) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:49.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:15:49.388+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:49.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:49.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:15:49.654+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:49.654+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:15:49.685+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:15:49.685+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:15:49.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.361 seconds
[2023-08-29T10:39:58.617+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:39:58.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:39:58.639+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:39:58.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:40:00.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:40:01.545+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:40:01.543+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:40:01.629+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:40:01.628+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:40:01.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 3.112 seconds
[2023-08-29T10:40:32.363+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:40:32.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:40:32.375+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:40:32.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:40:32.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:40:32.952+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:40:32.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:40:32.980+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:40:32.980+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:40:33.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.677 seconds
[2023-08-29T10:41:03.922+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:03.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:41:03.992+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:03.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:05.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:05.466+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:05.465+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:41:05.505+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:05.505+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:41:05.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.647 seconds
[2023-08-29T10:41:35.901+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:35.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:41:35.914+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:35.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:36.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:36.497+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:36.496+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:41:36.518+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:36.518+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:41:36.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.647 seconds
[2023-08-29T10:41:41.346+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:41.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:41:41.369+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:41.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:41.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:41:41.886+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:41.885+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:41:41.906+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:41:41.905+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:41:41.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.591 seconds
[2023-08-29T10:48:15.176+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:48:15.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:48:15.187+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:48:15.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:48:15.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:48:16.072+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:48:16.070+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:48:16.109+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:48:16.109+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:48:16.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.012 seconds
[2023-08-29T10:48:46.684+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:48:46.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:48:46.709+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:48:46.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:48:47.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:48:47.130+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:48:47.130+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:48:47.154+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:48:47.154+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:48:47.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.498 seconds
[2023-08-29T10:49:17.662+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:49:17.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:49:17.679+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:49:17.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:49:18.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:49:18.580+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:49:18.579+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:49:18.601+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:49:18.601+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:49:18.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.984 seconds
[2023-08-29T10:49:49.164+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:49:49.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:49:49.176+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:49:49.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:49:49.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:49:49.886+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:49:49.885+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:49:49.908+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:49:49.908+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:49:49.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.767 seconds
[2023-08-29T10:50:20.608+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:50:20.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:50:20.624+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:50:20.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:50:21.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:50:21.286+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:50:21.286+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:50:21.310+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:50:21.310+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:50:21.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.732 seconds
[2023-08-29T10:50:51.748+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:50:51.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:50:51.761+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:50:51.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:50:52.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:50:52.217+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:50:52.216+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:50:52.237+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:50:52.237+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:50:52.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.521 seconds
[2023-08-29T10:51:39.846+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:51:39.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:51:39.859+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:51:39.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:51:40.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:51:40.553+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:51:40.552+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:51:40.595+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:51:40.595+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:51:40.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.808 seconds
[2023-08-29T10:52:11.155+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:52:11.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:52:11.191+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:52:11.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:52:12.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:52:12.192+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:52:12.192+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:52:12.217+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:52:12.217+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:52:12.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.100 seconds
[2023-08-29T10:52:42.748+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:52:42.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:52:42.765+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:52:42.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:52:44.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:52:44.581+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:52:44.578+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:52:44.625+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:52:44.624+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:52:44.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.913 seconds
[2023-08-29T10:53:14.925+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:53:14.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:53:14.948+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:53:14.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:53:15.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:53:15.560+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:53:15.560+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:53:15.582+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:53:15.582+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:53:15.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.685 seconds
[2023-08-29T10:53:46.090+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:53:46.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:53:46.110+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:53:46.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:53:46.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:53:46.592+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:53:46.592+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:53:46.611+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:53:46.611+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:53:46.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.561 seconds
[2023-08-29T10:54:17.116+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:54:17.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-29T10:54:17.141+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:54:17.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:54:17.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-29T10:54:17.971+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:54:17.971+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-29T10:54:18.006+0000] {logging_mixin.py:151} INFO - [2023-08-29T10:54:18.006+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-29T10:54:18.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.921 seconds

[2023-08-31T03:40:51.309+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:40:51.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T03:40:51.327+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:40:51.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:40:52.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:40:52.304+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:40:52.303+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T03:40:52.343+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:40:52.343+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-08-31T03:40:52.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.122 seconds
[2023-08-31T03:41:22.889+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:41:22.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T03:41:22.910+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:41:22.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:41:23.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:41:23.854+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:41:23.853+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T03:41:23.874+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:41:23.874+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T03:41:23.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.024 seconds
[2023-08-31T03:41:54.155+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:41:54.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T03:41:54.175+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:41:54.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:41:54.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:41:54.368+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:41:54.368+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T03:41:54.409+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:41:54.409+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T03:41:54.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.282 seconds
[2023-08-31T03:42:24.829+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:42:24.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T03:42:24.848+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:42:24.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:42:25.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:42:25.101+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:42:25.100+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T03:42:25.123+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:42:25.123+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T03:42:25.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.322 seconds
[2023-08-31T03:42:39.957+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:42:39.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T03:42:40.015+0000] {logging_mixin.py:151} INFO - [2023-08-31T03:42:40.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T03:42:40.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:16.284+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:16.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:00:16.308+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:00:16.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:16.766+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:00:16.759+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 19, in <module>
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
AttributeError: type object 'datetime.datetime' has no attribute 'datetime'
[2023-08-31T04:00:16.770+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:16.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.545 seconds
[2023-08-31T04:00:47.296+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:47.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:00:47.311+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:00:47.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:47.868+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:00:47.851+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 19, in <module>
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
AttributeError: type object 'datetime.datetime' has no attribute 'datetime'
[2023-08-31T04:00:47.871+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:00:47.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.618 seconds
[2023-08-31T04:01:18.073+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:01:18.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:01:18.079+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:01:18.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:01:18.557+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:01:18.554+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 19, in <module>
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
AttributeError: type object 'datetime.datetime' has no attribute 'datetime'
[2023-08-31T04:01:18.572+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:01:18.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.533 seconds
[2023-08-31T04:01:48.955+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:01:48.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:01:48.965+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:01:48.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:01:49.373+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:01:49.369+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 19, in <module>
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
AttributeError: type object 'datetime.datetime' has no attribute 'datetime'
[2023-08-31T04:01:49.377+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:01:49.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.452 seconds
[2023-08-31T04:03:15.376+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:03:15.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:03:15.387+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:03:15.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:03:15.861+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:03:15.853+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 22, in <module>
    log_file_path = os.path.join(conf.get("core", "BASE_LOG_FOLDER"), f"my_custom_log_3108.txt")
NameError: name 'os' is not defined
[2023-08-31T04:03:15.866+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:03:15.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.531 seconds
[2023-08-31T04:03:46.365+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:03:46.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:03:46.375+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:03:46.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:03:46.677+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:03:46.674+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 22, in <module>
    log_file_path = os.path.join(conf.get("core", "BASE_LOG_FOLDER"), f"my_custom_log_3108.txt")
NameError: name 'os' is not defined
[2023-08-31T04:03:46.679+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:03:46.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.361 seconds
[2023-08-31T04:04:35.597+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:04:35.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:04:35.609+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:04:35.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:04:36.067+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:04:36.054+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 23, in <module>
    log_file_path = os.path.join(conf.get("core", "BASE_LOG_FOLDER"), f"my_custom_log_3108.txt")
NameError: name 'conf' is not defined
[2023-08-31T04:04:36.070+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:04:36.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.513 seconds
[2023-08-31T04:05:06.566+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:05:06.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:05:06.585+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:05:06.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:05:06.866+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:05:06.863+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 23, in <module>
    log_file_path = os.path.join(conf.get("core", "BASE_LOG_FOLDER"), f"my_custom_log_3108.txt")
NameError: name 'conf' is not defined
[2023-08-31T04:05:06.869+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:05:06.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.332 seconds
[2023-08-31T04:05:37.220+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:05:37.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:05:37.230+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:05:37.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:05:37.857+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:05:37.851+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 23, in <module>
    log_file_path = os.path.join(conf.get("core", "BASE_LOG_FOLDER"), f"my_custom_log_3108.txt")
NameError: name 'conf' is not defined
[2023-08-31T04:05:37.860+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:05:37.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.681 seconds
[2023-08-31T04:09:29.287+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:09:29.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:09:29.321+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:09:29.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:09:31.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:09:31.863+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:09:31.857+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:09:31.955+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:09:31.954+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:09:32.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.768 seconds
[2023-08-31T04:10:02.568+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:10:02.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:10:02.586+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:10:02.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:10:03.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:10:03.574+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:10:03.573+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:10:03.612+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:10:03.611+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:10:03.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.081 seconds
[2023-08-31T04:10:34.106+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:10:34.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:10:34.134+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:10:34.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:10:34.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:10:34.650+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:10:34.645+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:10:34.674+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:10:34.674+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:10:34.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.597 seconds
[2023-08-31T04:11:04.971+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:11:04.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:11:05.004+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:11:05.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:11:05.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:11:05.490+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:11:05.489+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:11:05.511+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:11:05.510+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:11:05.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.572 seconds
[2023-08-31T04:11:35.890+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:11:35.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:11:35.902+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:11:35.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:11:36.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:11:36.351+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:11:36.351+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:11:36.369+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:11:36.369+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:11:36.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.506 seconds
[2023-08-31T04:12:06.809+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:12:06.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:12:06.837+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:12:06.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:12:07.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:12:07.346+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:12:07.345+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:12:07.369+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:12:07.369+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:12:07.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.615 seconds
[2023-08-31T04:12:37.705+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:12:37.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:12:37.731+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:12:37.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:12:38.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:12:38.191+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:12:38.191+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:12:38.220+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:12:38.220+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:12:38.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.546 seconds
[2023-08-31T04:39:42.645+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:39:42.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:39:42.660+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:39:42.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:39:42.677+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:39:42.674+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 117
    provide_context=True,  # Pass the task context to the function
    ^
SyntaxError: invalid syntax
[2023-08-31T04:39:42.680+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:39:42.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.113 seconds
[2023-08-31T04:40:13.234+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:40:13.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:40:13.242+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:40:13.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:40:13.259+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:40:13.258+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 117
    provide_context=True,  # Pass the task context to the function
    ^
SyntaxError: invalid syntax
[2023-08-31T04:40:13.262+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:40:13.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.072 seconds
[2023-08-31T04:41:06.268+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:41:06.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:41:06.278+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:41:06.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:41:06.719+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:41:06.719+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:41:06.750+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:41:06.735+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'write_to_file': <Task(BashOperator): write_to_file>}
[2023-08-31T04:41:06.755+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:41:06.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.559 seconds
[2023-08-31T04:41:37.264+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:41:37.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:41:37.274+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:41:37.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:41:37.569+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:41:37.568+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:41:37.578+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:41:37.575+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'write_to_file': <Task(BashOperator): write_to_file>}
[2023-08-31T04:41:37.580+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:41:37.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.346 seconds
[2023-08-31T04:42:07.816+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:07.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:42:07.822+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:07.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:08.204+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:08.204+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:42:08.212+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:08.209+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'write_to_file': <Task(BashOperator): write_to_file>}
[2023-08-31T04:42:08.214+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:08.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.425 seconds
[2023-08-31T04:42:38.621+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:38.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:42:38.642+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:38.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:38.984+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:38.984+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:42:38.993+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:38.989+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'write_to_file': <Task(BashOperator): write_to_file>}
[2023-08-31T04:42:38.997+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:39.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.406 seconds
[2023-08-31T04:42:42.082+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:42.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:42:42.087+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:42.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:42.328+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:42.328+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:42:42.335+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:42:42.332+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'bash_command': <function extract_function at 0xffff71b21280>}
[2023-08-31T04:42:42.338+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:42:42.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.288 seconds
[2023-08-31T04:43:32.111+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:43:32.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:43:32.133+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:43:32.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:43:32.695+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:43:32.695+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:43:32.715+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:43:32.705+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'bash_command': <function extract_function at 0xffff7659f700>}
[2023-08-31T04:43:32.718+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:43:32.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.667 seconds
[2023-08-31T04:44:03.359+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:44:03.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:44:03.369+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:44:03.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:44:03.649+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:44:03.648+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:44:03.657+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:44:03.653+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data_using_BeautifulSoup.py", line 113, in <module>
    crawl_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: crawl_task). Invalid arguments were:
**kwargs: {'bash_command': <function extract_function at 0xffff7637a280>}
[2023-08-31T04:44:03.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:44:03.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.331 seconds
[2023-08-31T04:50:15.591+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:50:15.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:50:15.620+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:15.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:50:16.183+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:16.183+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:50:16.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:50:16.400+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:16.400+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:50:16.432+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:16.432+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:50:16.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.881 seconds
[2023-08-31T04:50:47.184+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:50:47.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:50:47.195+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:47.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:50:47.802+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:47.802+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:50:47.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:50:47.844+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:47.844+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:50:47.863+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:50:47.863+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:50:47.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.702 seconds
[2023-08-31T04:51:18.154+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:51:18.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:51:18.184+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:18.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:51:18.659+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:18.659+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:51:18.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:51:18.721+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:18.721+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:51:18.761+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:18.761+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:51:18.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.650 seconds
[2023-08-31T04:51:44.647+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:51:44.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:51:44.657+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:44.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:51:45.159+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:45.159+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:51:45.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:51:45.225+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:45.225+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:51:45.248+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:51:45.247+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:51:45.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.624 seconds
[2023-08-31T04:52:15.761+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:52:15.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:52:15.784+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:15.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:52:16.526+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:16.525+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:52:16.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:52:16.593+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:16.593+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:52:16.619+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:16.618+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:52:16.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.892 seconds
[2023-08-31T04:52:46.828+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:52:46.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:52:46.844+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:46.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:52:47.275+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:47.275+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:52:47.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:52:47.327+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:47.327+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:52:47.355+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:52:47.355+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:52:47.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.567 seconds
[2023-08-31T04:53:17.718+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:53:17.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:53:17.728+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:17.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:53:18.151+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:18.151+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:53:18.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:53:18.194+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:18.194+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:53:18.215+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:18.214+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:53:18.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.518 seconds
[2023-08-31T04:53:48.524+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:53:48.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:53:48.531+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:48.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:53:48.638+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:48.638+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:53:48.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:53:48.710+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:48.710+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:53:48.739+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:53:48.739+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:53:48.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.241 seconds
[2023-08-31T04:54:18.969+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:54:18.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:54:18.976+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:18.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:54:19.119+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:19.119+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:54:19.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:54:19.199+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:19.198+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:54:19.236+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:19.236+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:54:19.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.315 seconds
[2023-08-31T04:54:49.484+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:54:49.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:54:49.493+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:49.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:54:49.634+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:49.634+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:54:49.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:54:49.717+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:49.717+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:54:49.773+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:54:49.772+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:54:49.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.312 seconds
[2023-08-31T04:55:19.958+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:55:19.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:55:19.965+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:19.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:55:20.113+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:20.112+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:55:20.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:55:20.175+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:20.175+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:55:20.218+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:20.218+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:55:20.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.298 seconds
[2023-08-31T04:55:50.412+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:55:50.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:55:50.435+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:50.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:55:50.582+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:50.581+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:55:50.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:55:50.651+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:50.650+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:55:50.676+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:55:50.676+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:55:50.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.289 seconds
[2023-08-31T04:56:20.895+0000] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:56:20.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:56:20.905+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:20.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:56:21.055+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:21.055+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:56:21.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:56:21.121+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:21.121+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:56:21.152+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:21.151+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:56:21.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.281 seconds
[2023-08-31T04:56:51.372+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:56:51.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:56:51.389+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:51.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:56:51.529+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:51.529+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:56:51.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:56:51.590+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:51.590+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:56:51.617+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:56:51.617+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:56:51.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.277 seconds
[2023-08-31T04:57:21.814+0000] {processor.py:157} INFO - Started process (PID=153) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:57:21.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:57:21.821+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:21.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:57:21.956+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:21.956+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:57:21.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:57:22.026+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:22.026+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:57:22.059+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:22.059+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:57:22.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.270 seconds
[2023-08-31T04:57:52.326+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:57:52.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:57:52.336+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:52.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:57:52.446+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:52.445+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:57:52.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:57:52.501+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:52.501+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:57:52.528+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:57:52.528+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:57:52.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.235 seconds
[2023-08-31T04:58:22.957+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:58:22.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:58:22.979+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:22.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:58:23.084+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:23.083+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:58:23.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:58:23.143+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:23.143+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:58:23.169+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:23.169+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:58:23.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.234 seconds
[2023-08-31T04:58:53.671+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:58:53.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:58:53.681+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:53.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:58:53.818+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:53.818+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:58:53.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:58:53.891+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:53.891+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:58:53.920+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:58:53.920+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:58:53.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.283 seconds
[2023-08-31T04:59:24.090+0000] {processor.py:157} INFO - Started process (PID=189) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:59:24.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:59:24.097+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:24.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:59:24.218+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:24.218+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:59:24.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:59:24.280+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:24.280+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:59:24.307+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:24.307+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:59:24.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.245 seconds
[2023-08-31T04:59:54.609+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:59:54.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T04:59:54.619+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:54.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:59:54.749+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:54.748+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T04:59:54.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T04:59:54.849+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:54.849+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T04:59:54.879+0000] {logging_mixin.py:151} INFO - [2023-08-31T04:59:54.879+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T04:59:54.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.305 seconds
[2023-08-31T05:00:25.215+0000] {processor.py:157} INFO - Started process (PID=207) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:00:25.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:00:25.224+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:00:25.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:00:25.335+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:00:25.335+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T05:00:25.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:00:25.404+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:00:25.404+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:00:25.433+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:00:25.433+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:00:25.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.240 seconds
[2023-08-31T05:01:47.888+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:01:47.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:01:47.904+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:01:47.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:01:48.334+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:01:48.334+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T05:01:48.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:01:48.556+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:01:48.555+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:01:48.593+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:01:48.592+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:01:48.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.756 seconds
[2023-08-31T05:02:19.259+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:02:19.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:02:19.281+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:19.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:02:20.043+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:20.043+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T05:02:20.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:02:20.142+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:20.142+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:02:20.208+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:20.208+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:02:20.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.034 seconds
[2023-08-31T05:02:50.376+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:02:50.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:02:50.382+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:50.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:02:50.618+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:50.618+0000] {crawl_data_using_BeautifulSoup.py:36} WARNING - This log will not show up!
[2023-08-31T05:02:50.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:02:50.668+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:50.668+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:02:50.696+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:02:50.696+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:02:50.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.341 seconds
[2023-08-31T05:07:04.976+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:04.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:07:04.994+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:04.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:05.576+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:05.575+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:07:05.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:05.830+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:05.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:07:05.890+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:05.890+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:07:05.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.960 seconds
[2023-08-31T05:07:07.021+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:07.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:07:07.034+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:07.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:07.488+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:07.488+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:07:07.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:07.546+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:07.546+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:07:07.576+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:07.576+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:07:07.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.596 seconds
[2023-08-31T05:07:38.360+0000] {processor.py:157} INFO - Started process (PID=41) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:38.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:07:38.366+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:38.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:38.666+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:38.666+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:07:38.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:07:38.707+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:38.707+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:07:38.731+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:07:38.731+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:07:38.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.390 seconds
[2023-08-31T05:08:09.023+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:08:09.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:08:09.040+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:09.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:08:09.525+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:09.525+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:08:09.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:08:09.578+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:09.578+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:08:09.615+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:09.615+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:08:09.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.621 seconds
[2023-08-31T05:08:40.053+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:08:40.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:08:40.060+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:40.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:08:40.272+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:40.272+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:08:40.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:08:40.306+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:40.306+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:08:40.324+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:08:40.324+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:08:40.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.291 seconds
[2023-08-31T05:09:10.815+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:09:10.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:09:10.823+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:10.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:09:11.027+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:11.027+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:09:11.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:09:11.063+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:11.063+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:09:11.083+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:11.082+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:09:11.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.287 seconds
[2023-08-31T05:09:41.429+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:09:41.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:09:41.436+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:41.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:09:41.649+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:41.649+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:09:41.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:09:41.684+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:41.684+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:09:41.702+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:09:41.702+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:09:41.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.292 seconds
[2023-08-31T05:10:12.394+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:10:12.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:10:12.401+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:12.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:10:12.485+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:12.485+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:10:12.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:10:12.528+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:12.527+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:10:12.548+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:12.548+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:10:12.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.174 seconds
[2023-08-31T05:10:42.884+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:10:42.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:10:42.891+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:42.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:10:43.047+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:43.046+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:10:43.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:10:43.117+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:43.116+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:10:43.152+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:10:43.152+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:10:43.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.298 seconds
[2023-08-31T05:11:13.672+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:11:13.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:11:13.695+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:13.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:11:13.947+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:13.946+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:11:13.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:11:14.092+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:14.092+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:11:14.177+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:14.176+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:11:14.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.577 seconds
[2023-08-31T05:11:44.564+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:11:44.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:11:44.572+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:44.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:11:44.669+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:44.669+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:11:44.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:11:44.713+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:44.713+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:11:44.739+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:11:44.739+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:11:44.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.207 seconds
[2023-08-31T05:12:05.566+0000] {processor.py:157} INFO - Started process (PID=119) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:12:05.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:12:05.576+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:05.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:12:05.690+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:05.689+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:12:05.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:12:05.752+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:05.752+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:12:05.776+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:05.776+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:12:05.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.234 seconds
[2023-08-31T05:12:36.290+0000] {processor.py:157} INFO - Started process (PID=129) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:12:36.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:12:36.301+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:36.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:12:36.434+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:36.434+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:12:36.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:12:36.509+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:36.509+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:12:36.544+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:12:36.544+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:12:36.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.284 seconds
[2023-08-31T05:13:02.790+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:13:02.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:13:02.801+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:13:02.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:13:02.929+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:13:02.929+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:13:02.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:13:03.134+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:13:03.134+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:13:03.167+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:13:03.166+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:13:03.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.410 seconds
[2023-08-31T05:14:22.978+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:14:22.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:14:22.992+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:22.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:14:23.534+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:23.533+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:14:23.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:14:23.848+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:23.847+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:14:24.127+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:24.122+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:14:24.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.221 seconds
[2023-08-31T05:14:54.888+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:14:54.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:14:54.941+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:54.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:14:57.042+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:57.041+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:14:57.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:14:57.188+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:57.188+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:14:57.278+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:14:57.278+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:14:57.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.488 seconds
[2023-08-31T05:15:27.640+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:15:27.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:15:27.645+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:15:27.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:15:27.867+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:15:27.866+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:15:27.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:15:27.905+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:15:27.905+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:15:27.927+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:15:27.927+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:15:27.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.308 seconds
[2023-08-31T05:21:10.116+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:10.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:21:10.127+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:10.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:10.595+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:10.594+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:21:10.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:10.834+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:10.834+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:21:10.884+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:10.884+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:21:10.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.819 seconds
[2023-08-31T05:21:11.124+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:11.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:21:11.132+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:11.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:11.515+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:11.514+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:21:11.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:11.564+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:11.564+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:21:11.592+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:11.591+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:21:11.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.496 seconds
[2023-08-31T05:21:41.722+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:41.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:21:41.730+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:41.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:42.046+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:42.046+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:21:42.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:21:42.085+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:42.084+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:21:42.107+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:21:42.107+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:21:42.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.407 seconds
[2023-08-31T05:22:12.496+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:22:12.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-08-31T05:22:12.509+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:22:12.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:22:13.049+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:22:13.049+0000] {crawl_data_using_BeautifulSoup.py:87} WARNING - This log will not show up!
[2023-08-31T05:22:13.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-08-31T05:22:13.095+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:22:13.095+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-08-31T05:22:13.119+0000] {logging_mixin.py:151} INFO - [2023-08-31T05:22:13.118+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-31T00:00:00+00:00, run_after=2023-09-01T00:00:00+00:00
[2023-08-31T05:22:13.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.651 seconds

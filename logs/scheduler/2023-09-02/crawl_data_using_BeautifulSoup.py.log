[2023-09-02T00:05:13.992+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:13.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:05:14.008+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:14.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:14.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:15.143+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:15.142+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:05:15.186+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:15.186+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-01T00:00:00+00:00, run_after=2023-09-02T00:00:00+00:00
[2023-09-02T00:05:15.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.243 seconds
[2023-09-02T00:05:16.188+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:16.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:05:16.229+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:16.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:17.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:17.148+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:17.148+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:05:17.245+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:17.244+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:05:17.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.121 seconds
[2023-09-02T00:05:47.604+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:47.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:05:47.613+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:47.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:47.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:05:48.035+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:48.035+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:05:48.059+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:05:48.059+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:05:48.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.475 seconds
[2023-09-02T00:06:18.235+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:06:18.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:06:18.244+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:06:18.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:06:18.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:06:18.538+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:06:18.537+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:06:18.570+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:06:18.570+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:06:18.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.360 seconds
[2023-09-02T00:06:48.929+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:06:48.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:06:48.935+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:06:48.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:06:49.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:06:49.191+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:06:49.190+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:06:49.209+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:06:49.209+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:06:49.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.305 seconds
[2023-09-02T00:07:19.653+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:07:19.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:07:19.661+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:07:19.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:07:19.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:07:19.904+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:07:19.904+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:07:19.931+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:07:19.931+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:07:19.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.303 seconds
[2023-09-02T00:11:29.515+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:11:29.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:11:29.529+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:11:29.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:11:30.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:11:30.226+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:11:30.225+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:11:30.295+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:11:30.295+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:11:30.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.827 seconds
[2023-09-02T00:12:00.787+0000] {processor.py:157} INFO - Started process (PID=37) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:12:00.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:12:00.813+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:12:00.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:12:01.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:12:01.175+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:12:01.175+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:12:01.194+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:12:01.194+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:12:01.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.433 seconds
[2023-09-02T00:12:31.402+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:12:31.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:12:31.444+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:12:31.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:12:32.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:12:32.329+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:12:32.329+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:12:32.350+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:12:32.350+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:12:32.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.980 seconds
[2023-09-02T00:13:02.596+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:13:02.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:13:02.606+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:13:02.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:13:02.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:13:02.980+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:13:02.979+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:13:02.999+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:13:02.998+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:13:03.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.425 seconds
[2023-09-02T00:13:33.615+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:13:33.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:13:33.635+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:13:33.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:13:34.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:13:34.146+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:13:34.145+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:13:34.168+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:13:34.168+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:13:34.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.588 seconds
[2023-09-02T00:14:04.919+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:14:04.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:14:04.953+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:14:04.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:14:06.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:14:06.508+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:14:06.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:14:06.632+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:14:06.631+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:14:06.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.806 seconds
[2023-09-02T00:14:36.926+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:14:36.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:14:36.954+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:14:36.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:14:37.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:14:37.326+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:14:37.326+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:14:37.349+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:14:37.348+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:14:37.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.447 seconds
[2023-09-02T00:19:54.114+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:19:54.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:19:54.129+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:19:54.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:19:54.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:19:55.075+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:19:55.074+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:19:55.121+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:19:55.121+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:19:55.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.095 seconds
[2023-09-02T00:20:25.827+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:20:25.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:20:25.843+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:20:25.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:20:26.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:20:26.474+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:20:26.473+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:20:26.541+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:20:26.541+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:20:26.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.804 seconds
[2023-09-02T00:20:57.048+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:20:57.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:20:57.059+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:20:57.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:20:57.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:20:57.390+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:20:57.390+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:20:57.414+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:20:57.414+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:20:57.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.388 seconds
[2023-09-02T00:21:28.039+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:26:55.346+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:26:55.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:26:55.365+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:26:55.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:26:56.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:26:56.322+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:26:56.321+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:26:56.379+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:26:56.379+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:26:56.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.115 seconds
[2023-09-02T00:27:27.273+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:27:27.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:27:27.298+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:27:27.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:27:28.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:27:28.597+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:27:28.597+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:27:28.627+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:27:28.627+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:27:28.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.390 seconds
[2023-09-02T00:27:58.926+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:27:58.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:27:58.943+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:27:58.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:27:59.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:27:59.241+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:27:59.240+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:27:59.261+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:27:59.261+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:27:59.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.357 seconds
[2023-09-02T00:29:03.662+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:29:03.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:29:03.690+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:29:03.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:29:04.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:29:04.575+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:29:04.573+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:29:04.673+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:29:04.672+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:29:04.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.124 seconds
[2023-09-02T00:29:35.563+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:29:35.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:29:35.578+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:29:35.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:29:36.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:29:36.281+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:29:36.280+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:29:36.304+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:29:36.304+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:29:36.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.787 seconds
[2023-09-02T00:30:06.595+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:06.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:30:06.601+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:06.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:06.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:06.884+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:06.883+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:30:06.907+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:06.907+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:30:06.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.334 seconds
[2023-09-02T00:30:20.273+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:20.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:30:20.283+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:20.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:20.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:20.808+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:20.807+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:30:20.841+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:20.841+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:30:20.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.598 seconds
[2023-09-02T00:30:51.763+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:51.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:30:51.787+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:51.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:52.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:30:52.607+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:52.604+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:30:52.662+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:30:52.662+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:30:52.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.979 seconds
[2023-09-02T00:31:23.199+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:31:23.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:31:23.210+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:31:23.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:31:23.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:31:23.645+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:31:23.645+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:31:23.667+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:31:23.667+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:31:23.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.490 seconds
[2023-09-02T00:32:57.666+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:32:57.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:32:57.677+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:32:57.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:32:58.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:32:58.314+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:32:58.313+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:32:58.349+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:32:58.349+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:32:58.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.734 seconds
[2023-09-02T00:33:28.780+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:33:28.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:33:28.794+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:33:28.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:33:29.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:33:29.191+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:33:29.191+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:33:29.214+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:33:29.214+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:33:29.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.474 seconds
[2023-09-02T00:33:59.444+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:33:59.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:33:59.457+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:33:59.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:33:59.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:33:59.897+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:33:59.896+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:33:59.915+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:33:59.915+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:33:59.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.500 seconds
[2023-09-02T00:34:30.117+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:34:30.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:34:30.133+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:34:30.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:34:31.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:34:31.141+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:34:31.140+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:34:31.160+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:34:31.160+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:34:31.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.068 seconds
[2023-09-02T00:35:01.708+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:35:01.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:35:01.722+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:35:01.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:35:02.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:35:02.156+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:35:02.155+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:35:02.179+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:35:02.178+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:35:02.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.508 seconds
[2023-09-02T00:35:32.513+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:35:32.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:35:32.550+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:35:32.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:35:33.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:35:33.322+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:35:33.321+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:35:33.356+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:35:33.356+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:35:33.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.882 seconds
[2023-09-02T00:36:03.669+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:36:03.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:36:03.718+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:36:03.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:36:04.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:36:05.061+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:36:05.060+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:36:05.091+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:36:05.091+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:36:05.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.460 seconds
[2023-09-02T00:36:35.436+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:36:35.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:36:35.453+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:36:35.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:36:35.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:36:35.661+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:36:35.661+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:36:35.683+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:36:35.683+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:36:35.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.279 seconds
[2023-09-02T00:37:06.110+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:37:06.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:37:06.126+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:37:06.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:37:06.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:37:06.339+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:37:06.339+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:37:06.362+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:37:06.361+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:37:06.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.298 seconds
[2023-09-02T00:37:36.771+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:37:36.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:37:36.785+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:37:36.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:37:36.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:37:36.999+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:37:36.999+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:37:37.024+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:37:37.024+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:37:37.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.285 seconds
[2023-09-02T00:38:05.469+0000] {processor.py:157} INFO - Started process (PID=121) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:38:05.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:38:05.480+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:38:05.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:38:05.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:38:05.693+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:38:05.692+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:38:05.740+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:38:05.740+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:38:05.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.311 seconds
[2023-09-02T00:39:26.085+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:39:26.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:39:26.100+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:39:26.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:39:26.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:39:26.820+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:39:26.819+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:39:26.883+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:39:26.883+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:39:26.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.852 seconds
[2023-09-02T00:39:57.652+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:39:57.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:39:57.680+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:39:57.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:39:58.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:39:58.504+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:39:58.504+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:39:58.522+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:39:58.522+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:39:58.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.891 seconds
[2023-09-02T00:52:00.752+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:52:00.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:52:00.767+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:52:00.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:52:01.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:52:01.739+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:52:01.738+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:52:01.773+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:52:01.773+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:52:01.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.078 seconds
[2023-09-02T00:52:32.410+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:52:32.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:52:32.420+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:52:32.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:52:32.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:52:32.938+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:52:32.937+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:52:32.957+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:52:32.957+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:52:32.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.571 seconds
[2023-09-02T00:53:03.284+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:53:03.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:53:03.313+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:53:03.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:53:03.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:53:03.589+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:53:03.589+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:53:03.608+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:53:03.608+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:53:03.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.344 seconds
[2023-09-02T00:53:34.211+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:53:34.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:53:34.242+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:53:34.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:53:35.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:53:35.134+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:53:35.134+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:53:35.160+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:53:35.160+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:53:35.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.023 seconds
[2023-09-02T00:54:05.700+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:54:05.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:54:05.707+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:54:05.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:54:06.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:54:06.116+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:54:06.116+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:54:06.135+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:54:06.135+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:54:06.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.456 seconds
[2023-09-02T00:54:36.489+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:54:36.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:54:36.500+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:54:36.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:54:36.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:54:36.893+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:54:36.893+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:54:36.915+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:54:36.915+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:54:36.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.445 seconds
[2023-09-02T00:55:07.599+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:55:07.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:55:07.611+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:55:07.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:55:07.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:55:07.745+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:55:07.744+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:55:07.778+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:55:07.778+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:55:07.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.206 seconds
[2023-09-02T00:55:38.173+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:55:38.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:55:38.192+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:55:38.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:55:38.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:55:38.349+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:55:38.348+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:55:38.373+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:55:38.373+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:55:38.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.224 seconds
[2023-09-02T00:56:08.760+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:08.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:56:08.783+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:08.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:08.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:09.020+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:09.019+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:56:09.065+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:09.065+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:56:09.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.342 seconds
[2023-09-02T00:56:39.565+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:39.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:56:39.579+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:39.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:39.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:39.792+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:39.792+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:56:39.821+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:39.820+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:56:39.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.290 seconds
[2023-09-02T00:56:46.995+0000] {processor.py:157} INFO - Started process (PID=113) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:46.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:56:47.006+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:47.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:47.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:47.235+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:47.234+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:56:47.275+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:47.274+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:56:47.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.321 seconds
[2023-09-02T00:56:48.363+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:48.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:56:48.369+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:48.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:48.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:56:48.537+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:48.537+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:56:48.565+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:56:48.565+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:56:48.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.228 seconds
[2023-09-02T00:57:54.445+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:57:54.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:57:54.464+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:57:54.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:57:54.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:57:55.197+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:57:55.196+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:57:55.249+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:57:55.248+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:57:55.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.845 seconds
[2023-09-02T00:57:55.415+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:57:55.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:57:55.425+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:57:55.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:57:55.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:57:55.845+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:57:55.844+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:57:55.881+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:57:55.880+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:57:55.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.503 seconds
[2023-09-02T00:58:26.443+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:58:26.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:58:26.469+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:58:26.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:58:26.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:58:26.868+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:58:26.867+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:58:26.888+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:58:26.888+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:58:26.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.467 seconds
[2023-09-02T00:58:57.030+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:58:57.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:58:57.036+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:58:57.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:58:57.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:58:57.297+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:58:57.296+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:58:57.318+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:58:57.318+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:58:57.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.309 seconds
[2023-09-02T00:59:27.807+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:59:27.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:59:27.831+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:59:27.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:59:28.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:59:28.555+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:59:28.554+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:59:28.579+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:59:28.579+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:59:28.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.820 seconds
[2023-09-02T00:59:58.977+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:59:58.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T00:59:58.991+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:59:58.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:59:59.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T00:59:59.491+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:59:59.491+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T00:59:59.512+0000] {logging_mixin.py:151} INFO - [2023-09-02T00:59:59.512+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T00:59:59.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.563 seconds
[2023-09-02T01:00:29.908+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:00:29.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:00:29.922+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:00:29.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:00:30.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:00:30.525+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:00:30.524+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:00:30.551+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:00:30.551+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:00:30.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.672 seconds
[2023-09-02T01:01:01.334+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:01:01.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:01:01.353+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:01:01.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:01:01.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:01:01.706+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:01:01.705+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:01:01.741+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:01:01.741+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:01:01.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.470 seconds
[2023-09-02T01:01:32.078+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:01:32.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:01:32.090+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:01:32.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:01:32.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:01:32.244+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:01:32.244+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:01:32.265+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:01:32.265+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:01:32.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.208 seconds
[2023-09-02T01:02:02.718+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:02:02.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:02:02.729+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:02:02.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:02:02.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:02:02.915+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:02:02.915+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:02:02.937+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:02:02.937+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:02:02.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.243 seconds
[2023-09-02T01:02:33.320+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:02:33.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:02:33.333+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:02:33.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:02:33.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:02:33.508+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:02:33.507+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:02:33.529+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:02:33.529+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:02:33.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.232 seconds
[2023-09-02T01:03:04.071+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:03:04.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:03:04.086+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:03:04.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:03:04.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:03:04.267+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:03:04.267+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:03:04.289+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:03:04.288+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:03:04.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.239 seconds
[2023-09-02T01:03:34.716+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:03:34.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:03:34.738+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:03:34.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:03:34.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:03:34.994+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:03:34.994+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:03:35.026+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:03:35.026+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:03:35.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.357 seconds
[2023-09-02T01:04:05.464+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:04:05.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:04:05.490+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:04:05.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:04:05.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:04:05.693+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:04:05.692+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:04:05.714+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:04:05.714+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:04:05.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.285 seconds
[2023-09-02T01:04:36.067+0000] {processor.py:157} INFO - Started process (PID=152) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:04:36.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:04:36.087+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:04:36.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:04:36.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:04:36.302+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:04:36.302+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:04:36.333+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:04:36.333+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:04:36.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.301 seconds
[2023-09-02T01:05:06.754+0000] {processor.py:157} INFO - Started process (PID=161) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:05:06.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:05:06.770+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:05:06.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:05:06.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:05:06.981+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:05:06.981+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:05:07.007+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:05:07.006+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:05:07.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.277 seconds
[2023-09-02T01:05:37.418+0000] {processor.py:157} INFO - Started process (PID=170) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:05:37.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:05:37.436+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:05:37.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:05:37.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:05:37.637+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:05:37.636+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:05:37.663+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:05:37.663+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:05:37.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.272 seconds
[2023-09-02T01:06:08.114+0000] {processor.py:157} INFO - Started process (PID=179) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:06:08.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:06:08.125+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:06:08.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:06:08.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:06:08.337+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:06:08.336+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:06:08.364+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:06:08.364+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:06:08.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.284 seconds
[2023-09-02T01:06:38.814+0000] {processor.py:157} INFO - Started process (PID=188) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:06:38.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:06:38.837+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:06:38.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:06:38.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:06:39.055+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:06:39.055+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:06:39.082+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:06:39.082+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:06:39.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.319 seconds
[2023-09-02T01:07:09.455+0000] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:07:09.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:07:09.469+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:07:09.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:07:09.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:07:09.683+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:07:09.683+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:07:09.707+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:07:09.707+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:07:09.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.279 seconds
[2023-09-02T01:07:40.137+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:07:40.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:07:40.151+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:07:40.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:07:40.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:07:40.341+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:07:40.341+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:07:40.363+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:07:40.363+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:07:40.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.257 seconds
[2023-09-02T01:08:10.886+0000] {processor.py:157} INFO - Started process (PID=215) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:08:10.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:08:10.901+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:08:10.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:08:11.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:08:11.087+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:08:11.087+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:08:11.119+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:08:11.119+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:08:11.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.259 seconds
[2023-09-02T01:08:41.454+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:08:41.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:08:41.487+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:08:41.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:08:41.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:08:41.680+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:08:41.678+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:08:41.708+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:08:41.707+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:08:41.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.285 seconds
[2023-09-02T01:09:12.165+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:09:12.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:09:12.177+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:09:12.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:09:12.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:09:12.370+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:09:12.369+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:09:12.398+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:09:12.398+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:09:12.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.262 seconds
[2023-09-02T01:09:42.878+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:09:42.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:09:42.890+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:09:42.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:09:43.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:09:43.098+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:09:43.097+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:09:43.123+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:09:43.123+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:09:43.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.275 seconds
[2023-09-02T01:10:13.558+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:10:13.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:10:13.568+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:10:13.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:10:13.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:10:13.765+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:10:13.764+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:10:13.785+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:10:13.785+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:10:13.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.257 seconds
[2023-09-02T01:10:44.198+0000] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:10:44.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:10:44.216+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:10:44.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:10:44.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:10:44.437+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:10:44.436+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:10:44.517+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:10:44.515+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:10:44.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.467 seconds
[2023-09-02T01:11:14.817+0000] {processor.py:157} INFO - Started process (PID=273) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:11:14.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:11:14.832+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:11:14.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:11:15.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:11:15.077+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:11:15.076+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:11:15.104+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:11:15.103+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:11:15.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.315 seconds
[2023-09-02T01:11:45.538+0000] {processor.py:157} INFO - Started process (PID=282) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:11:45.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:11:45.552+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:11:45.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:11:45.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:11:45.769+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:11:45.768+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:11:45.794+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:11:45.794+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:11:45.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.293 seconds
[2023-09-02T01:12:16.233+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:12:16.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:12:16.248+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:12:16.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:12:16.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:12:16.482+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:12:16.481+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:12:16.515+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:12:16.515+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:12:16.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.315 seconds
[2023-09-02T01:12:46.823+0000] {processor.py:157} INFO - Started process (PID=300) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:12:46.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:12:46.835+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:12:46.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:12:46.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:12:47.046+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:12:47.046+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:12:47.080+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:12:47.079+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:12:47.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.287 seconds
[2023-09-02T01:13:17.521+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:13:17.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:13:17.532+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:13:17.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:13:17.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:13:17.714+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:13:17.713+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:13:17.739+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:13:17.739+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:13:17.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.243 seconds
[2023-09-02T01:13:48.094+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:13:48.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:13:48.110+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:13:48.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:13:48.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:13:48.261+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:13:48.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:13:48.282+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:13:48.282+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:13:48.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.209 seconds
[2023-09-02T01:14:18.617+0000] {processor.py:157} INFO - Started process (PID=327) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:14:18.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:14:18.630+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:14:18.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:14:18.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:14:18.784+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:14:18.783+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:14:18.805+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:14:18.805+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:14:18.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.209 seconds
[2023-09-02T01:14:49.262+0000] {processor.py:157} INFO - Started process (PID=336) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:14:49.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:14:49.288+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:14:49.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:14:49.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:14:49.526+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:14:49.526+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:14:49.570+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:14:49.569+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:14:49.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.349 seconds
[2023-09-02T01:15:20.050+0000] {processor.py:157} INFO - Started process (PID=345) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:15:20.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:15:20.083+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:15:20.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:15:20.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:15:20.292+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:15:20.292+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:15:20.327+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:15:20.327+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:15:20.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.302 seconds
[2023-09-02T01:15:50.686+0000] {processor.py:157} INFO - Started process (PID=354) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:15:50.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:15:50.697+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:15:50.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:15:50.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:15:50.907+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:15:50.907+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:15:50.930+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:15:50.929+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:15:50.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.266 seconds
[2023-09-02T01:16:21.408+0000] {processor.py:157} INFO - Started process (PID=363) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:16:21.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:16:21.437+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:16:21.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:16:21.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:16:21.640+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:16:21.640+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:16:21.669+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:16:21.668+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:16:21.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.289 seconds
[2023-09-02T01:16:52.079+0000] {processor.py:157} INFO - Started process (PID=372) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:16:52.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:16:52.101+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:16:52.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:16:52.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:16:52.299+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:16:52.298+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:16:52.321+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:16:52.321+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:16:52.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.270 seconds
[2023-09-02T01:17:22.760+0000] {processor.py:157} INFO - Started process (PID=381) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:17:22.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:17:22.773+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:17:22.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:17:22.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:17:22.962+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:17:22.961+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:17:22.986+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:17:22.986+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:17:23.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.273 seconds
[2023-09-02T01:17:53.432+0000] {processor.py:157} INFO - Started process (PID=390) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:17:53.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:17:53.450+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:17:53.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:17:53.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:17:53.647+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:17:53.647+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:17:53.669+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:17:53.669+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:17:53.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.259 seconds
[2023-09-02T01:18:24.169+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:18:24.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:18:24.182+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:18:24.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:18:24.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:18:24.399+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:18:24.398+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:18:24.426+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:18:24.426+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:18:24.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.282 seconds
[2023-09-02T01:18:55.017+0000] {processor.py:157} INFO - Started process (PID=408) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:18:55.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:18:55.049+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:18:55.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:18:55.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:18:55.262+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:18:55.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:18:55.286+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:18:55.285+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:18:55.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.296 seconds
[2023-09-02T01:19:25.761+0000] {processor.py:157} INFO - Started process (PID=417) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:19:25.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:19:25.772+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:19:25.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:19:25.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:19:25.964+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:19:25.963+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:19:25.985+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:19:25.985+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:19:26.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.248 seconds
[2023-09-02T01:19:56.409+0000] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:19:56.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:19:56.439+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:19:56.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:19:56.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:19:56.652+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:19:56.652+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:19:56.673+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:19:56.672+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:19:56.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.295 seconds
[2023-09-02T01:20:27.000+0000] {processor.py:157} INFO - Started process (PID=435) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:20:27.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:20:27.021+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:20:27.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:20:27.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:20:27.206+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:20:27.205+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:20:27.232+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:20:27.232+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:20:27.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.258 seconds
[2023-09-02T01:20:57.679+0000] {processor.py:157} INFO - Started process (PID=444) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:20:57.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:20:57.696+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:20:57.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:20:57.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:20:57.874+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:20:57.874+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:20:57.895+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:20:57.894+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:20:57.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.238 seconds
[2023-09-02T01:21:28.309+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:21:28.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:21:28.320+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:21:28.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:21:28.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:21:28.493+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:21:28.492+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:21:28.524+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:21:28.524+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:21:28.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.240 seconds
[2023-09-02T01:21:58.992+0000] {processor.py:157} INFO - Started process (PID=463) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:21:58.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:21:59.005+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:21:59.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:21:59.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:21:59.206+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:21:59.206+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:21:59.230+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:21:59.230+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:21:59.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.276 seconds
[2023-09-02T01:22:29.618+0000] {processor.py:157} INFO - Started process (PID=472) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:22:29.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:22:29.630+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:22:29.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:22:29.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:22:29.849+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:22:29.847+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:22:29.871+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:22:29.870+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:22:29.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.278 seconds
[2023-09-02T01:23:00.357+0000] {processor.py:157} INFO - Started process (PID=482) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:23:00.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:23:00.369+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:23:00.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:23:00.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:23:00.536+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:23:00.535+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:23:00.563+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:23:00.563+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:23:00.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.244 seconds
[2023-09-02T01:23:30.844+0000] {processor.py:157} INFO - Started process (PID=491) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:23:30.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:23:30.858+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:23:30.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:23:30.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:23:31.024+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:23:31.024+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:23:31.047+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:23:31.046+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:23:31.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.234 seconds
[2023-09-02T01:24:01.447+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:24:01.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:24:01.458+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:24:01.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:24:01.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:24:01.637+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:24:01.636+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:24:01.659+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:24:01.659+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:24:01.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.238 seconds
[2023-09-02T01:24:32.104+0000] {processor.py:157} INFO - Started process (PID=508) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:24:32.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:24:32.113+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:24:32.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:24:32.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:24:32.263+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:24:32.262+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:24:32.298+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:24:32.298+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:24:32.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.214 seconds
[2023-09-02T01:25:02.647+0000] {processor.py:157} INFO - Started process (PID=517) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:25:02.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:25:02.655+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:25:02.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:25:02.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:25:02.818+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:25:02.816+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:25:02.843+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:25:02.843+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:25:02.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.225 seconds
[2023-09-02T01:25:33.257+0000] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:25:33.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:25:33.266+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:25:33.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:25:33.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:25:33.455+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:25:33.454+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:25:33.477+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:25:33.477+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:25:33.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.245 seconds
[2023-09-02T01:26:03.852+0000] {processor.py:157} INFO - Started process (PID=535) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:26:03.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:26:03.877+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:26:03.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:26:03.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:26:04.019+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:26:04.019+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:26:04.051+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:26:04.051+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:26:04.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.223 seconds
[2023-09-02T01:26:34.467+0000] {processor.py:157} INFO - Started process (PID=544) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:26:34.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:26:34.483+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:26:34.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:26:34.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:26:34.752+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:26:34.751+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:26:34.785+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:26:34.785+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:26:34.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.348 seconds
[2023-09-02T01:27:05.197+0000] {processor.py:157} INFO - Started process (PID=553) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:27:05.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:27:05.209+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:27:05.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:27:05.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:27:05.481+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:27:05.480+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:27:05.515+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:27:05.515+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:27:05.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.351 seconds
[2023-09-02T01:27:35.969+0000] {processor.py:157} INFO - Started process (PID=562) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:27:35.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:27:35.979+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:27:35.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:27:36.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:27:36.162+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:27:36.162+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:27:36.186+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:27:36.186+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:27:36.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.244 seconds
[2023-09-02T01:28:06.763+0000] {processor.py:157} INFO - Started process (PID=571) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:28:06.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:28:06.782+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:28:06.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:28:06.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:28:06.969+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:28:06.969+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:28:06.994+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:28:06.993+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:28:07.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.261 seconds
[2023-09-02T01:28:37.437+0000] {processor.py:157} INFO - Started process (PID=580) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:28:37.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:28:37.453+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:28:37.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:28:37.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:28:37.636+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:28:37.635+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:28:37.661+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:28:37.661+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:28:37.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.246 seconds
[2023-09-02T01:29:08.057+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:29:08.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:29:08.067+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:29:08.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:29:08.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:29:08.259+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:29:08.258+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:29:08.283+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:29:08.283+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:29:08.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.249 seconds
[2023-09-02T01:29:38.808+0000] {processor.py:157} INFO - Started process (PID=598) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:29:38.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:29:38.819+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:29:38.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:29:38.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:29:39.009+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:29:39.008+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:29:39.033+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:29:39.033+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:29:39.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.255 seconds
[2023-09-02T01:30:09.420+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:30:09.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:30:09.429+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:30:09.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:30:09.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:30:09.638+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:30:09.638+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:30:09.660+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:30:09.660+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:30:09.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.263 seconds
[2023-09-02T01:30:40.139+0000] {processor.py:157} INFO - Started process (PID=614) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:30:40.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:30:40.154+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:30:40.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:30:40.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:30:40.371+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:30:40.371+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:30:40.401+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:30:40.401+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:30:40.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.295 seconds
[2023-09-02T01:31:11.045+0000] {processor.py:157} INFO - Started process (PID=623) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:31:11.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T01:31:11.062+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:31:11.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:31:11.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T01:31:11.325+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:31:11.324+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T01:31:11.360+0000] {logging_mixin.py:151} INFO - [2023-09-02T01:31:11.360+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T01:31:11.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.359 seconds
[2023-09-02T02:36:31.315+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T02:36:31.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T02:36:31.362+0000] {logging_mixin.py:151} INFO - [2023-09-02T02:36:31.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T02:36:31.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T02:36:31.800+0000] {logging_mixin.py:151} INFO - [2023-09-02T02:36:31.799+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T02:36:31.890+0000] {logging_mixin.py:151} INFO - [2023-09-02T02:36:31.890+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T02:36:31.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.658 seconds
[2023-09-02T03:10:28.105+0000] {processor.py:157} INFO - Started process (PID=641) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:10:28.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:10:28.132+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:10:28.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:10:28.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:10:28.639+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:10:28.638+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:10:28.692+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:10:28.691+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:10:28.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.661 seconds
[2023-09-02T03:10:59.027+0000] {processor.py:157} INFO - Started process (PID=650) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:10:59.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:10:59.068+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:10:59.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:10:59.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:10:59.297+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:10:59.296+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:10:59.323+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:10:59.322+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:10:59.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.323 seconds
[2023-09-02T03:11:29.750+0000] {processor.py:157} INFO - Started process (PID=659) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:11:29.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:11:29.763+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:11:29.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:11:29.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:11:29.990+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:11:29.989+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:11:30.011+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:11:30.011+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:11:30.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.295 seconds
[2023-09-02T03:12:00.443+0000] {processor.py:157} INFO - Started process (PID=668) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:12:00.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:12:00.465+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:12:00.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:12:00.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:12:00.706+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:12:00.705+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:12:00.735+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:12:00.735+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:12:00.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.327 seconds
[2023-09-02T03:12:31.309+0000] {processor.py:157} INFO - Started process (PID=677) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:12:31.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:12:31.324+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:12:31.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:12:31.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:12:31.546+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:12:31.545+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:12:31.582+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:12:31.582+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:12:31.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.300 seconds
[2023-09-02T03:13:01.997+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:13:02.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:13:02.017+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:13:02.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:13:02.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:13:02.261+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:13:02.259+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:13:02.295+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:13:02.295+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:13:02.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.338 seconds
[2023-09-02T03:13:32.714+0000] {processor.py:157} INFO - Started process (PID=695) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:13:32.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:13:32.732+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:13:32.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:13:32.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:13:33.047+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:13:33.046+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:13:33.076+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:13:33.076+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:13:33.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.399 seconds
[2023-09-02T03:14:03.444+0000] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:14:03.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:14:03.454+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:14:03.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:14:03.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:14:03.655+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:14:03.654+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:14:03.677+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:14:03.677+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:14:03.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.261 seconds
[2023-09-02T03:14:34.061+0000] {processor.py:157} INFO - Started process (PID=713) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:14:34.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:14:34.076+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:14:34.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:14:34.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:14:34.271+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:14:34.270+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:14:34.309+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:14:34.309+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:14:34.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.286 seconds
[2023-09-02T03:15:04.751+0000] {processor.py:157} INFO - Started process (PID=722) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:15:04.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:15:04.768+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:15:04.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:15:04.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:15:05.009+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:15:05.009+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:15:05.035+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:15:05.035+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:15:05.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.330 seconds
[2023-09-02T03:15:35.564+0000] {processor.py:157} INFO - Started process (PID=731) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:15:35.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:15:35.588+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:15:35.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:15:35.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:15:35.823+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:15:35.822+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:15:35.848+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:15:35.848+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:15:35.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.323 seconds
[2023-09-02T03:16:06.956+0000] {processor.py:157} INFO - Started process (PID=740) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:16:06.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:16:06.979+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:16:06.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:16:07.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:16:07.322+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:16:07.320+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:16:07.356+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:16:07.355+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:16:07.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.437 seconds
[2023-09-02T03:16:37.782+0000] {processor.py:157} INFO - Started process (PID=749) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:16:37.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:16:37.792+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:16:37.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:16:37.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:16:37.967+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:16:37.967+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:16:37.994+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:16:37.994+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:16:38.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.235 seconds
[2023-09-02T03:17:08.340+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:17:08.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:17:08.349+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:17:08.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:17:08.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:17:08.504+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:17:08.503+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:17:08.526+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:17:08.526+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:17:08.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.207 seconds
[2023-09-02T03:17:38.773+0000] {processor.py:157} INFO - Started process (PID=768) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:17:38.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:17:38.797+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:17:38.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:17:39.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:17:39.132+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:17:39.131+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:17:39.187+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:17:39.187+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:17:39.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.467 seconds
[2023-09-02T03:18:09.665+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:18:09.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:18:09.686+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:18:09.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:18:09.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:18:09.947+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:18:09.946+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:18:09.978+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:18:09.977+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:18:09.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.348 seconds
[2023-09-02T03:18:40.508+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:18:40.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:18:40.525+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:18:40.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:18:40.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:18:40.755+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:18:40.755+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:18:40.782+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:18:40.782+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:18:40.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.299 seconds
[2023-09-02T03:19:11.299+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:19:11.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:19:11.314+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:19:11.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:19:11.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:19:11.535+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:19:11.534+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:19:11.557+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:19:11.556+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:19:11.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.283 seconds
[2023-09-02T03:19:41.986+0000] {processor.py:157} INFO - Started process (PID=804) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:19:41.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:19:42.005+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:19:42.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:19:42.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:19:42.207+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:19:42.206+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:19:42.242+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:19:42.242+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:19:42.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.313 seconds
[2023-09-02T03:20:12.650+0000] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:20:12.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:20:12.661+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:20:12.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:20:12.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:20:12.882+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:20:12.880+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:20:12.903+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:20:12.903+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:20:12.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.289 seconds
[2023-09-02T03:20:43.506+0000] {processor.py:157} INFO - Started process (PID=822) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:20:43.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:20:43.521+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:20:43.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:20:43.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:20:43.737+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:20:43.736+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:20:43.767+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:20:43.766+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:20:43.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.294 seconds
[2023-09-02T03:21:14.218+0000] {processor.py:157} INFO - Started process (PID=831) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:21:14.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:21:14.232+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:21:14.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:21:14.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:21:14.440+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:21:14.439+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:21:14.461+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:21:14.460+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:21:14.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.279 seconds
[2023-09-02T03:21:45.322+0000] {processor.py:157} INFO - Started process (PID=839) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:21:45.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:21:45.347+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:21:45.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:21:45.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:21:45.641+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:21:45.640+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:21:45.682+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:21:45.681+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:21:45.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.407 seconds
[2023-09-02T03:22:16.127+0000] {processor.py:157} INFO - Started process (PID=848) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:22:16.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:22:16.142+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:22:16.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:22:16.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:22:16.359+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:22:16.359+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:22:16.391+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:22:16.391+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:22:16.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.293 seconds
[2023-09-02T03:22:47.283+0000] {processor.py:157} INFO - Started process (PID=857) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:22:47.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:22:47.355+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:22:47.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:22:47.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:22:48.819+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:22:48.813+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:22:49.081+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:22:49.078+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:22:49.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.980 seconds
[2023-09-02T03:23:19.802+0000] {processor.py:157} INFO - Started process (PID=865) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:23:19.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:23:19.820+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:23:19.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:23:20.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:23:20.065+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:23:20.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:23:20.089+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:23:20.089+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:23:20.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.331 seconds
[2023-09-02T03:23:50.904+0000] {processor.py:157} INFO - Started process (PID=874) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:23:50.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:23:50.923+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:23:50.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:23:51.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:23:51.276+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:23:51.275+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:23:51.312+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:23:51.312+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:23:51.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.457 seconds
[2023-09-02T03:24:21.834+0000] {processor.py:157} INFO - Started process (PID=883) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:24:21.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:24:21.852+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:24:21.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:24:22.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:24:22.079+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:24:22.078+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:24:22.114+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:24:22.114+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:24:22.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.312 seconds
[2023-09-02T03:24:52.814+0000] {processor.py:157} INFO - Started process (PID=893) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:24:52.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:24:52.839+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:24:52.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:24:53.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:24:53.143+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:24:53.142+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:24:53.166+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:24:53.166+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:24:53.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.402 seconds
[2023-09-02T03:25:23.807+0000] {processor.py:157} INFO - Started process (PID=901) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:25:23.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:25:23.819+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:25:23.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:25:23.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:25:23.998+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:25:23.998+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:25:24.021+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:25:24.021+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:25:24.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.237 seconds
[2023-09-02T03:25:54.517+0000] {processor.py:157} INFO - Started process (PID=910) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:25:54.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:25:54.526+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:25:54.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:25:54.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:25:54.760+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:25:54.759+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:25:54.783+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:25:54.783+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:25:54.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.299 seconds
[2023-09-02T03:26:25.809+0000] {processor.py:157} INFO - Started process (PID=919) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:26:25.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:26:25.821+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:26:25.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:26:25.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:26:25.971+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:26:25.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:26:25.991+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:26:25.991+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:26:26.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.205 seconds
[2023-09-02T03:26:56.356+0000] {processor.py:157} INFO - Started process (PID=928) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:26:56.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:26:56.362+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:26:56.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:26:56.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:26:56.499+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:26:56.499+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:26:56.519+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:26:56.518+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:26:56.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.181 seconds
[2023-09-02T03:27:26.887+0000] {processor.py:157} INFO - Started process (PID=937) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:27:26.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:27:26.893+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:27:26.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:27:26.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:27:27.025+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:27:27.025+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:27:27.047+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:27:27.047+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:27:27.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.182 seconds
[2023-09-02T03:27:57.374+0000] {processor.py:157} INFO - Started process (PID=946) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:27:57.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:27:57.386+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:27:57.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:27:57.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:27:57.519+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:27:57.518+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:27:57.540+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:27:57.540+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:27:57.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.185 seconds
[2023-09-02T03:28:27.845+0000] {processor.py:157} INFO - Started process (PID=956) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:28:27.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:28:27.858+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:28:27.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:28:27.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:28:27.980+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:28:27.980+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:28:28.001+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:28:28.001+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:28:28.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.176 seconds
[2023-09-02T03:28:58.418+0000] {processor.py:157} INFO - Started process (PID=965) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:28:58.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:28:58.423+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:28:58.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:28:58.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:28:58.555+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:28:58.554+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:28:58.577+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:28:58.577+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:28:58.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.186 seconds
[2023-09-02T03:29:28.890+0000] {processor.py:157} INFO - Started process (PID=974) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:29:28.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:29:28.896+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:29:28.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:29:29.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:29:29.059+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:29:29.058+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:29:29.088+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:29:29.088+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:29:29.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.221 seconds
[2023-09-02T03:29:59.447+0000] {processor.py:157} INFO - Started process (PID=983) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:29:59.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:29:59.472+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:29:59.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:29:59.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:29:59.607+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:29:59.606+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:29:59.630+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:29:59.630+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:29:59.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.203 seconds
[2023-09-02T03:30:29.932+0000] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:30:29.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:30:29.958+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:30:29.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:30:30.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:30:30.088+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:30:30.087+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:30:30.111+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:30:30.111+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:30:30.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.204 seconds
[2023-09-02T03:31:00.531+0000] {processor.py:157} INFO - Started process (PID=1001) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:31:00.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:31:00.543+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:31:00.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:31:00.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:31:00.672+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:31:00.671+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:31:00.692+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:31:00.692+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:31:00.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.180 seconds
[2023-09-02T03:31:31.100+0000] {processor.py:157} INFO - Started process (PID=1010) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:31:31.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:31:31.111+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:31:31.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:31:31.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:31:31.363+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:31:31.362+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:31:31.408+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:31:31.407+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:31:31.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.338 seconds
[2023-09-02T03:32:01.991+0000] {processor.py:157} INFO - Started process (PID=1019) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:32:01.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:32:02.007+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:32:02.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:32:02.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:32:02.237+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:32:02.236+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:32:02.260+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:32:02.260+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:32:02.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.300 seconds
[2023-09-02T03:32:32.640+0000] {processor.py:157} INFO - Started process (PID=1028) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:32:32.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:32:32.647+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:32:32.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:32:32.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:32:32.776+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:32:32.775+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:32:32.797+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:32:32.797+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:32:32.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.183 seconds
[2023-09-02T03:33:03.175+0000] {processor.py:157} INFO - Started process (PID=1037) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:33:03.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:33:03.185+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:33:03.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:33:03.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:33:03.367+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:33:03.366+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:33:03.401+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:33:03.401+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:33:03.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.251 seconds
[2023-09-02T03:33:33.717+0000] {processor.py:157} INFO - Started process (PID=1046) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:33:33.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:33:33.747+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:33:33.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:33:33.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:33:33.897+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:33:33.896+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:33:33.918+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:33:33.918+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:33:33.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.226 seconds
[2023-09-02T03:34:04.275+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:34:04.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T03:34:04.283+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:34:04.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:34:04.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T03:34:04.465+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:34:04.463+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T03:34:04.487+0000] {logging_mixin.py:151} INFO - [2023-09-02T03:34:04.487+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T03:34:04.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.234 seconds
[2023-09-02T10:10:07.031+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:10:07.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:10:07.046+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:10:07.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:10:07.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:10:08.126+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:10:08.125+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:10:08.156+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:10:08.155+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:10:08.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.236 seconds
[2023-09-02T10:10:39.207+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:10:39.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:10:39.229+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:10:39.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:10:39.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:10:39.909+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:10:39.908+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:10:39.929+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:10:39.929+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:10:39.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.758 seconds
[2023-09-02T10:11:42.240+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:11:42.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:11:42.252+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:11:42.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:11:42.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:11:43.135+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:11:43.134+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:11:43.152+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:11:43.151+0000] {dag.py:2929} INFO - Creating ORM DAG for website_crawler
[2023-09-02T10:11:43.180+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:11:43.179+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-09-02T10:11:43.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.986 seconds
[2023-09-02T10:12:14.005+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:12:14.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:12:14.117+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:12:14.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:12:16.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:12:16.798+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:12:16.797+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:12:16.834+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:12:16.833+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-08-28T00:00:00+00:00, run_after=2023-08-29T00:00:00+00:00
[2023-09-02T10:12:16.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 3.061 seconds
[2023-09-02T10:12:48.050+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:12:48.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:12:48.194+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:12:48.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:13:05.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:13:05.646+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:13:05.643+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:13:05.725+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:13:05.724+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:13:05.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 17.830 seconds
[2023-09-02T10:13:32.144+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:13:32.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:13:32.346+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:13:32.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:13:48.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:13:50.277+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:13:50.263+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:13:51.703+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:13:51.637+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:13:52.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 20.282 seconds
[2023-09-02T10:13:55.758+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:13:56.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:13:56.793+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:13:56.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:09.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:18.158+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:18.070+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:14:18.467+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:18.461+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:14:18.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 23.278 seconds
[2023-09-02T10:14:21.063+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:21.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:14:21.169+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:21.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:24.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:24.172+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:24.171+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:14:24.245+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:24.245+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:14:24.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 3.393 seconds
[2023-09-02T10:14:55.294+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:55.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:14:55.311+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:55.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:55.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:14:55.590+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:55.589+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:14:55.635+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:14:55.635+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:14:55.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.401 seconds
[2023-09-02T10:15:25.793+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:15:25.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:15:25.803+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:15:25.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:15:25.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:15:25.987+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:15:25.987+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:15:26.027+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:15:26.027+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:15:26.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.266 seconds
[2023-09-02T10:15:56.357+0000] {processor.py:157} INFO - Started process (PID=105) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:15:56.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:15:56.372+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:15:56.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:15:56.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:15:56.594+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:15:56.593+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:15:56.630+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:15:56.629+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:15:56.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.301 seconds
[2023-09-02T10:16:26.829+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:16:26.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:16:26.842+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:16:26.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:16:27.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:16:27.063+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:16:27.062+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:16:27.094+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:16:27.093+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:16:27.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.293 seconds
[2023-09-02T10:17:35.066+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:17:35.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:17:35.079+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:17:35.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:17:35.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:17:35.813+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:17:35.811+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:17:35.894+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:17:35.894+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:17:35.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.910 seconds
[2023-09-02T10:18:06.391+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:18:06.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:18:06.399+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:18:06.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:18:06.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:18:06.742+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:18:06.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:18:06.761+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:18:06.761+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:18:06.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.393 seconds
[2023-09-02T10:18:36.991+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:18:36.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:18:37.003+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:18:37.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:18:37.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:18:37.554+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:18:37.553+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:18:37.574+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:18:37.574+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:18:37.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.604 seconds
[2023-09-02T10:19:08.294+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:19:08.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:19:08.340+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:19:08.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:19:10.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:19:10.696+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:19:10.696+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:19:10.728+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:19:10.728+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:19:10.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.495 seconds
[2023-09-02T10:19:41.042+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:19:41.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:19:41.053+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:19:41.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:19:41.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:19:41.803+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:19:41.803+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:19:41.822+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:19:41.822+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:19:41.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.804 seconds
[2023-09-02T10:20:09.254+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:09.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:20:09.268+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:09.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:09.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:09.551+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:09.550+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:20:09.582+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:09.582+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:20:09.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.384 seconds
[2023-09-02T10:20:17.845+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:17.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:20:17.853+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:17.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:17.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:18.011+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:18.011+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:20:18.032+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:18.032+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:20:18.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.212 seconds
[2023-09-02T10:20:48.212+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:48.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:20:48.222+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:48.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:48.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:20:48.390+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:48.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:20:48.421+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:20:48.421+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:20:48.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.236 seconds
[2023-09-02T10:21:18.831+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:21:18.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:21:18.860+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:21:18.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:21:18.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:21:19.039+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:21:19.039+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:21:19.068+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:21:19.068+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:21:19.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.262 seconds
[2023-09-02T10:21:49.472+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:21:49.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T10:21:49.481+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:21:49.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:21:49.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T10:21:49.626+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:21:49.626+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T10:21:49.646+0000] {logging_mixin.py:151} INFO - [2023-09-02T10:21:49.646+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T10:21:49.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.196 seconds
[2023-09-02T11:01:16.663+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:01:16.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:01:16.678+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:01:16.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:01:17.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:01:17.704+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:01:17.704+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:01:17.746+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:01:17.745+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:01:17.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.121 seconds
[2023-09-02T11:01:48.505+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:01:48.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:01:48.546+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:01:48.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:01:49.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:01:49.325+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:01:49.323+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:01:49.364+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:01:49.364+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:01:49.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.894 seconds
[2023-09-02T11:02:20.338+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:02:20.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:02:20.380+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:02:20.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:02:23.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:02:23.469+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:02:23.467+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:02:23.531+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:02:23.531+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:02:23.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 3.281 seconds
[2023-09-02T11:02:54.100+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:02:54.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:02:54.111+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:02:54.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:02:54.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:02:54.922+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:02:54.921+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:02:54.944+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:02:54.944+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:02:54.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.871 seconds
[2023-09-02T11:03:00.706+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:00.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:03:00.715+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:00.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:01.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:01.183+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:01.182+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:03:01.207+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:01.207+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:03:01.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.523 seconds
[2023-09-02T11:03:09.822+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:09.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:03:09.834+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:09.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:10.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:10.245+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:10.244+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:03:10.269+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:10.268+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:03:10.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.475 seconds
[2023-09-02T11:03:41.199+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:41.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:03:41.207+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:41.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:03:41.375+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:41.375+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:03:41.401+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:03:41.401+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:03:41.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.225 seconds
[2023-09-02T11:04:11.806+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:04:11.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:04:11.818+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:04:11.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:04:11.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:04:12.011+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:04:12.011+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:04:12.040+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:04:12.040+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:04:12.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.270 seconds
[2023-09-02T11:04:42.733+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:04:42.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:04:42.744+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:04:42.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:04:42.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:04:42.975+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:04:42.974+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:04:43.009+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:04:43.008+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:04:43.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.315 seconds
[2023-09-02T11:05:13.268+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:13.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:05:13.281+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:13.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:13.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:13.518+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:13.517+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:05:13.565+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:13.565+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:05:13.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.326 seconds
[2023-09-02T11:05:23.450+0000] {processor.py:157} INFO - Started process (PID=105) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:23.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:05:23.463+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:23.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:23.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:23.700+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:23.699+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:05:23.734+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:23.734+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:05:23.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.323 seconds
[2023-09-02T11:05:33.805+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:33.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:05:33.811+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:33.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:33.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:05:33.952+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:33.951+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:05:33.973+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:05:33.973+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:05:33.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.191 seconds
[2023-09-02T11:06:04.415+0000] {processor.py:157} INFO - Started process (PID=122) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:06:04.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:06:04.427+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:06:04.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:06:04.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:06:04.620+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:06:04.620+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:06:04.648+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:06:04.648+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:06:04.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.265 seconds
[2023-09-02T11:06:35.128+0000] {processor.py:157} INFO - Started process (PID=131) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:06:35.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:06:35.150+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:06:35.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:06:35.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:06:35.291+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:06:35.291+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:06:35.315+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:06:35.314+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:06:35.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.210 seconds
[2023-09-02T11:07:05.912+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:07:05.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T11:07:05.922+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:07:05.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:07:06.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T11:07:06.089+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:07:06.088+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T11:07:06.120+0000] {logging_mixin.py:151} INFO - [2023-09-02T11:07:06.120+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T11:07:06.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.239 seconds
[2023-09-02T12:30:53.612+0000] {processor.py:157} INFO - Started process (PID=140) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T12:30:53.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T12:30:53.643+0000] {logging_mixin.py:151} INFO - [2023-09-02T12:30:53.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T12:30:54.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T12:30:54.302+0000] {logging_mixin.py:151} INFO - [2023-09-02T12:30:54.300+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T12:30:54.373+0000] {logging_mixin.py:151} INFO - [2023-09-02T12:30:54.372+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T12:30:54.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.901 seconds
[2023-09-02T12:54:39.916+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T12:54:39.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T12:54:39.954+0000] {logging_mixin.py:151} INFO - [2023-09-02T12:54:39.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T12:54:40.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T12:54:40.390+0000] {logging_mixin.py:151} INFO - [2023-09-02T12:54:40.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T12:54:40.460+0000] {logging_mixin.py:151} INFO - [2023-09-02T12:54:40.460+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T12:54:40.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.641 seconds
[2023-09-02T13:23:00.722+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:23:00.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:23:00.746+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:23:00.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:23:01.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:23:01.631+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:23:01.630+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:23:01.699+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:23:01.698+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:23:01.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.037 seconds
[2023-09-02T13:23:32.747+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:23:32.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:23:32.794+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:23:32.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:23:33.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:23:33.610+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:23:33.609+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:23:33.635+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:23:33.635+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:23:33.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.956 seconds
[2023-09-02T13:24:04.375+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:24:04.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:24:04.394+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:24:04.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:24:05.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:24:05.538+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:24:05.537+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:24:05.560+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:24:05.560+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:24:05.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.235 seconds
[2023-09-02T13:25:29.771+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:25:29.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:25:29.784+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:25:29.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:25:30.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:25:30.658+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:25:30.657+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:25:30.715+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:25:30.715+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:25:30.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.023 seconds
[2023-09-02T13:26:01.095+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:26:01.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:26:01.108+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:26:01.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:26:01.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:26:01.559+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:26:01.558+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:26:01.579+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:26:01.579+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:26:01.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.509 seconds
[2023-09-02T13:26:32.073+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:26:32.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:26:32.100+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:26:32.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:26:34.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:26:34.150+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:26:34.149+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:26:34.183+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:26:34.182+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:26:34.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 2.156 seconds
[2023-09-02T13:27:04.695+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:04.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:27:04.730+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:04.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:05.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:05.413+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:05.412+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:27:05.436+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:05.436+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:27:05.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.778 seconds
[2023-09-02T13:27:12.236+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:12.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:27:12.278+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:12.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:12.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:12.802+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:12.801+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:27:12.834+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:12.834+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:27:12.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.626 seconds
[2023-09-02T13:27:43.547+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:43.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:27:43.555+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:43.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:43.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:27:43.703+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:43.703+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:27:43.729+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:27:43.728+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:27:43.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.204 seconds
[2023-09-02T13:28:03.009+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:28:03.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:28:03.055+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:28:03.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:28:03.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:28:03.289+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:28:03.288+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:28:03.327+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:28:03.327+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:28:03.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.367 seconds
[2023-09-02T13:29:14.914+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:29:14.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:29:14.929+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:29:14.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:29:15.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:29:15.812+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:29:15.811+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:29:15.860+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:29:15.859+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:29:15.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.001 seconds
[2023-09-02T13:29:46.811+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:29:46.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:29:46.828+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:29:46.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:29:47.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:29:47.798+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:29:47.797+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:29:47.824+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:29:47.824+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:29:47.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.056 seconds
[2023-09-02T13:30:56.743+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:30:56.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:30:56.754+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:30:56.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:30:57.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:30:57.357+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:30:57.356+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:30:57.392+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:30:57.392+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:30:57.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.697 seconds
[2023-09-02T13:31:28.226+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:31:28.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:31:28.240+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:31:28.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:31:28.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:31:28.980+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:31:28.977+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:31:29.024+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:31:29.024+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:31:29.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.835 seconds
[2023-09-02T13:31:59.614+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:31:59.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:31:59.632+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:31:59.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:00.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:00.631+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:00.630+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:32:00.650+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:00.649+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:32:00.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.062 seconds
[2023-09-02T13:32:30.138+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:30.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:32:30.148+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:30.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:30.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:30.679+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:30.679+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:32:30.702+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:30.702+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:32:30.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.588 seconds
[2023-09-02T13:32:37.580+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:37.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:32:37.590+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:37.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:38.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:32:38.124+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:38.122+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:32:38.151+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:32:38.151+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:32:38.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.606 seconds
[2023-09-02T13:33:47.030+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:33:47.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:33:47.055+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:33:47.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:33:48.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:33:48.617+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:33:48.616+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:33:48.655+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:33:48.654+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:33:48.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.686 seconds
[2023-09-02T13:34:19.066+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:34:19.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:34:19.081+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:34:19.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:34:19.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:34:19.564+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:34:19.563+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:34:19.585+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:34:19.585+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:34:19.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.559 seconds
[2023-09-02T13:34:49.755+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:34:49.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:34:49.770+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:34:49.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:34:50.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:34:50.851+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:34:50.850+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:34:50.930+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:34:50.930+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:34:50.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.229 seconds
[2023-09-02T13:35:21.519+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:35:21.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:35:21.541+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:35:21.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:35:22.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:35:22.244+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:35:22.244+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:35:22.277+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:35:22.277+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:35:22.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.795 seconds
[2023-09-02T13:35:53.061+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:35:53.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:35:53.072+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:35:53.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:35:53.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:35:53.636+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:35:53.635+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:35:53.655+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:35:53.655+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:35:53.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.617 seconds
[2023-09-02T13:36:24.359+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:36:24.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:36:24.367+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:36:24.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:36:24.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:36:24.548+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:36:24.548+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:36:24.568+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:36:24.568+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:36:24.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.235 seconds
[2023-09-02T13:39:50.921+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:39:50.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:39:50.947+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:39:50.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:39:51.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:39:52.244+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:39:52.242+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:39:52.273+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:39:52.273+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:39:52.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.396 seconds
[2023-09-02T13:40:22.986+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:40:22.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:40:23.013+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:40:23.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:40:23.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:40:23.613+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:40:23.613+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:40:23.632+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:40:23.632+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:40:23.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.700 seconds
[2023-09-02T13:40:54.277+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:40:54.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:40:54.297+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:40:54.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:40:55.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:40:55.287+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:40:55.287+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:40:55.306+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:40:55.306+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:40:55.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.059 seconds
[2023-09-02T13:41:25.675+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:41:25.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:41:25.692+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:41:25.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:41:26.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:41:26.053+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:41:26.052+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:41:26.075+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:41:26.075+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:41:26.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.421 seconds
[2023-09-02T13:43:20.188+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:43:20.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:43:20.199+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:43:20.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:43:20.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:43:21.142+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:43:21.141+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:43:21.191+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:43:21.190+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:43:21.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.095 seconds
[2023-09-02T13:43:51.836+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:43:51.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:43:51.860+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:43:51.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:43:52.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:43:52.533+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:43:52.533+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:43:52.554+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:43:52.554+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:43:52.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.759 seconds
[2023-09-02T13:44:23.156+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:44:23.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:44:23.187+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:44:23.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:44:24.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:44:24.765+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:44:24.760+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:44:24.857+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:44:24.856+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:44:24.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.736 seconds
[2023-09-02T13:44:55.272+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:44:55.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:44:55.285+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:44:55.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:44:55.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:44:55.631+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:44:55.631+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:44:55.650+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:44:55.650+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:44:55.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.403 seconds
[2023-09-02T13:51:40.868+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:51:40.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:51:40.879+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:51:40.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:51:41.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:51:41.661+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:51:41.659+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:51:41.705+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:51:41.705+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:51:41.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.902 seconds
[2023-09-02T13:52:12.167+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:52:12.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:52:12.183+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:52:12.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:52:12.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:52:12.503+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:52:12.502+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:52:12.523+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:52:12.523+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:52:12.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.378 seconds
[2023-09-02T13:52:43.518+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:52:43.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:52:43.581+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:52:43.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:52:45.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:52:45.228+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:52:45.228+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:52:45.254+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:52:45.253+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:52:45.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.780 seconds
[2023-09-02T13:53:15.540+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:53:15.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:53:15.548+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:53:15.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:53:15.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:53:15.904+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:53:15.903+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:53:15.924+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:53:15.924+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:53:15.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.405 seconds
[2023-09-02T13:53:46.547+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:53:46.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:53:46.573+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:53:46.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:53:47.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:53:47.244+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:53:47.243+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:53:47.281+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:53:47.281+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:53:47.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.797 seconds
[2023-09-02T13:54:17.886+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:54:17.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:54:17.903+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:54:17.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:54:18.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:54:18.214+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:54:18.213+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:54:18.258+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:54:18.257+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:54:18.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.410 seconds
[2023-09-02T13:54:48.709+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:54:48.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T13:54:48.722+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:54:48.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:54:48.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T13:54:48.953+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:54:48.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T13:54:48.975+0000] {logging_mixin.py:151} INFO - [2023-09-02T13:54:48.975+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T13:54:48.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.300 seconds
[2023-09-02T14:04:52.912+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:04:52.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:04:52.925+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:04:52.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:04:53.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:04:53.883+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:04:53.882+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:04:53.934+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:04:53.933+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:04:54.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.123 seconds
[2023-09-02T14:05:24.524+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:05:24.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:05:24.534+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:05:24.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:05:24.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:05:24.861+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:05:24.861+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:05:24.879+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:05:24.879+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:05:24.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.381 seconds
[2023-09-02T14:05:55.199+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:05:55.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:05:55.210+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:05:55.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:05:55.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:05:55.758+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:05:55.757+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:05:55.778+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:05:55.778+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:05:55.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.606 seconds
[2023-09-02T14:06:26.243+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:06:26.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:06:26.254+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:06:26.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:06:26.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:06:26.696+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:06:26.695+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:06:26.715+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:06:26.715+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:06:26.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.507 seconds
[2023-09-02T14:06:57.196+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:06:57.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:06:57.214+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:06:57.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:06:57.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:06:57.999+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:06:57.999+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:06:58.017+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:06:58.017+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:06:58.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.866 seconds
[2023-09-02T14:07:28.741+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:07:28.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:07:28.757+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:07:28.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:07:28.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:07:28.946+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:07:28.946+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:07:28.966+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:07:28.966+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:07:28.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.251 seconds
[2023-09-02T14:07:59.602+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:07:59.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:07:59.671+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:07:59.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:08:00.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:08:00.649+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:08:00.640+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:08:00.769+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:08:00.768+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:08:00.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 1.321 seconds
[2023-09-02T14:08:31.541+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:08:31.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:08:31.576+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:08:31.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:08:31.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:08:31.998+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:08:31.997+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:08:32.043+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:08:32.043+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:08:32.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.552 seconds
[2023-09-02T14:09:02.522+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:09:02.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:09:02.644+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:09:02.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:09:03.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:09:03.167+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:09:03.166+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:09:03.284+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:09:03.283+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:09:03.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.847 seconds
[2023-09-02T14:09:33.739+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:09:33.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:09:33.755+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:09:33.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:09:33.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:09:34.000+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:09:34.000+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:09:34.035+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:09:34.035+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:09:34.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.329 seconds
[2023-09-02T14:10:04.579+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:10:04.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawl_data_using_BeautifulSoup.py for tasks to queue
[2023-09-02T14:10:04.591+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:10:04.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:10:04.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['website_crawler']) retrieved from /opt/airflow/dags/crawl_data_using_BeautifulSoup.py
[2023-09-02T14:10:04.860+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:10:04.860+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-02T14:10:04.884+0000] {logging_mixin.py:151} INFO - [2023-09-02T14:10:04.883+0000] {dag.py:3677} INFO - Setting next_dagrun for website_crawler to 2023-09-02T00:00:00+00:00, run_after=2023-09-03T00:00:00+00:00
[2023-09-02T14:10:04.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/crawl_data_using_BeautifulSoup.py took 0.334 seconds
